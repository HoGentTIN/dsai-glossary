{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inhoud/Content","text":""},{"location":"#nederlands","title":"Nederlands","text":"<p>Lijst van vaktermen die gebruikt worden in de cursus Data Science &amp; AI, met vertaling tussen Nederlands en Engels. Deze is nog in actieve ontwikkeling en wordt nog stelselmatig uitgebreid.</p> <p> NL Index</p> <p>Als je fouten of onduidelijkheden opmerkt, aarzel niet deze te melden als een  Issue!</p>"},{"location":"#english","title":"English","text":"<p>List of terms used in the the Data Science &amp; AI course, with translation between Dutch and English. This is still under active development and will be systematically expanded.</p> <p> EN Index</p> <p>If you notice any errors or ambiguities, don't hesitate to report them as an  Issue!</p>"},{"location":"index-en/","title":"Index - en","text":""},{"location":"index-en/#a","title":"A","text":"<ul> <li>association</li> <li>alternative hypothesis</li> <li>analysis, bivariate</li> </ul>"},{"location":"index-en/#b","title":"B","text":"<ul> <li>bar chart</li> <li>boxplot</li> </ul>"},{"location":"index-en/#c","title":"C","text":"<ul> <li>correlation</li> <li>Cohen's d</li> <li>contingency table</li> <li>Cramer's V</li> <li>Cochran's rules</li> <li>confidence interval</li> <li>critical region</li> <li>central limit theorem</li> <li>chi squared</li> <li>chi-squared test</li> <li>confidence level</li> <li>critical value</li> <li>chi-squared distribution</li> </ul>"},{"location":"index-en/#e","title":"E","text":"<ul> <li>effect size</li> </ul>"},{"location":"index-en/#f","title":"F","text":"<ul> <li>frequency</li> </ul>"},{"location":"index-en/#g","title":"G","text":"<ul> <li>Greek alphabet</li> </ul>"},{"location":"index-en/#h","title":"H","text":"<ul> <li>hypothesis test</li> <li>histogram</li> </ul>"},{"location":"index-en/#i","title":"I","text":"<ul> <li>interquartile range</li> </ul>"},{"location":"index-en/#k","title":"K","text":"<ul> <li>kernel density estimation plot</li> </ul>"},{"location":"index-en/#l","title":"L","text":"<ul> <li>level of measurement</li> </ul>"},{"location":"index-en/#m","title":"M","text":"<ul> <li>median</li> <li>measure of dispersion</li> <li>mode</li> <li>mosaic plot</li> <li>mean</li> <li>marginals</li> <li>measure of central tendency, mean</li> </ul>"},{"location":"index-en/#n","title":"N","text":"<ul> <li>null hypothesis</li> <li>normal distribution</li> <li>notation</li> </ul>"},{"location":"index-en/#o","title":"O","text":"<ul> <li>observation</li> </ul>"},{"location":"index-en/#p","title":"P","text":"<ul> <li>point estimate</li> <li>population</li> <li>probability distribution</li> <li>percentile</li> <li>probability</li> <li>p-value</li> </ul>"},{"location":"index-en/#r","title":"R","text":"<ul> <li>range</li> <li>residuals, standardized</li> <li>region of acceptance</li> </ul>"},{"location":"index-en/#s","title":"S","text":"<ul> <li>sample frame</li> <li>scatter plot</li> <li>sample size</li> <li>standard error</li> <li>sampling errors</li> <li>significance level</li> <li>sample, representative</li> <li>sample</li> <li>sample, random</li> </ul>"},{"location":"index-en/#t","title":"T","text":"<ul> <li>t-test</li> <li>t-distribution</li> <li>test statistic</li> </ul>"},{"location":"index-en/#v","title":"V","text":"<ul> <li>random variable</li> <li>variance</li> <li>value, expected</li> </ul>"},{"location":"index-en/#z","title":"Z","text":"<ul> <li>z-test</li> <li>z-score</li> </ul>"},{"location":"index-nl/","title":"Index - nl","text":""},{"location":"index-nl/#a","title":"A","text":"<ul> <li>aanvaardingsgebied</li> <li>alternatieve hypothese</li> <li>analyse van twee variabelen</li> </ul>"},{"location":"index-nl/#b","title":"B","text":"<ul> <li>betrouwbaarheidsinterval</li> <li>betrouwbaarheidsniveau</li> <li>bereik</li> <li>boxplot</li> </ul>"},{"location":"index-nl/#c","title":"C","text":"<ul> <li>Cohen's d</li> <li>chi-kwadraatverdeling</li> <li>correlatie</li> <li>Cramer's V</li> <li>centrale limietstelling</li> <li>Cochran's regels</li> <li>centrummaat</li> <li>chi-kwadraat</li> <li>chi-kwadraattoets</li> </ul>"},{"location":"index-nl/#e","title":"E","text":"<ul> <li>effectgrootte</li> </ul>"},{"location":"index-nl/#f","title":"F","text":"<ul> <li>frequentie</li> </ul>"},{"location":"index-nl/#g","title":"G","text":"<ul> <li>Het Griekse alfabet</li> <li>gemiddelde</li> </ul>"},{"location":"index-nl/#h","title":"H","text":"<ul> <li>hypothesetoets</li> <li>histogram</li> </ul>"},{"location":"index-nl/#i","title":"I","text":"<ul> <li>interkwartielafstand (IQR)</li> </ul>"},{"location":"index-nl/#k","title":"K","text":"<ul> <li>kerndichtheidsschattingsdiagram</li> <li>kans, waarschijnlijkheid</li> <li>kritieke gebied</li> <li>kruistabel</li> <li>kansverdeling</li> <li>kritieke grenswaarde</li> </ul>"},{"location":"index-nl/#m","title":"M","text":"<ul> <li>marginalen</li> <li>modus</li> <li>mozaiekdiagram</li> <li>meetniveau</li> <li>mediaan</li> </ul>"},{"location":"index-nl/#n","title":"N","text":"<ul> <li>nulhypothese</li> <li>normale verdeling</li> <li>notatie</li> </ul>"},{"location":"index-nl/#o","title":"O","text":"<ul> <li>overschrijdingskans</li> </ul>"},{"location":"index-nl/#p","title":"P","text":"<ul> <li>populatie</li> <li>puntschatter</li> <li>percentiel</li> </ul>"},{"location":"index-nl/#r","title":"R","text":"<ul> <li>residuen, gestandaardiseerde</li> </ul>"},{"location":"index-nl/#s","title":"S","text":"<ul> <li>steekproef, aselecte</li> <li>steekproefkader</li> <li>spreidingsmaat</li> <li>staafdiagram</li> <li>steekproefgrootte</li> <li>steekproef, representatieve</li> <li>significantieniveau</li> <li>spreidingsdiagram</li> <li>steekproeffouten</li> <li>steekproef</li> <li>standaardfout</li> </ul>"},{"location":"index-nl/#t","title":"T","text":"<ul> <li>toetsingsgrootheid</li> <li>t-verdeling</li> <li>t-toets</li> </ul>"},{"location":"index-nl/#v","title":"V","text":"<ul> <li>verband</li> <li>stochastische variabele</li> <li>variantie</li> </ul>"},{"location":"index-nl/#w","title":"W","text":"<ul> <li>waarde, verwachte</li> <li>waarneming</li> </ul>"},{"location":"index-nl/#z","title":"Z","text":"<ul> <li>z-score</li> <li>z-toets</li> </ul>"},{"location":"en/alternative-hypothesis/","title":"alternative hypothesis","text":"<p>(NL: alternatieve hypothese)</p> <p>In the context of a statistical hypothesis test, the alternative hypothesis (often written as \\(H_1\\)) is an assumption about a population parameter that we want to test.</p> <p>The alternative hypothesis usually represents the assumption that there is a significant difference between the population parameter and a given value, or that there is a relationship between two variables.</p> <p>The procedure of the test is based on the assumption that the null hypothesis is true. If we then encounter a contradiction, the null hypothesis is rejected and the alternative hypothesis is accepted.</p>"},{"location":"en/analysis-bivariate/","title":"analysis, bivariate","text":"<p>(NL: analyse van twee variabelen)</p> <p>Bivariate analysis is a collection of techniques used to investigate the relationship or association between two variables. Depending on the research question, one of the variables is considered the independent variable, and the other the dependent variable.</p> <p>Suitable techniques for visualizing or analyzing two variables depend on the measurement level of the variables involved. In this course, we limit ourselves to the techniques summarized in the tables below.</p>"},{"location":"en/analysis-bivariate/#data-visualisation-techniques","title":"Data visualisation techniques","text":"Independent variable Dependent variable Technique Qualitative Qualitative Clustered bar chart \" \" Stacked bar chart \" \" Mosaic plot Qualitative Quantitative Box plot \" \" Density plot Quantitative Quantitative Scatter plot"},{"location":"en/analysis-bivariate/#techniques-for-data-analysis","title":"Techniques for data analysis","text":"Independent variable Dependent variable Test Measure Qualitative Qualitative Independence test Cram\u00e9r's V Qualitative Quantitative T-test Cohen's d Quantitative Quantitative Correlation coefficient <ul> <li>In the case of two quantitative variables, in this course we only investigate whether a linear relationship exists between the two variables.</li> <li>Note that there is indeed a statistical testing procedure to investigate linear correlation, but it is not covered in this course.</li> </ul>"},{"location":"en/association/","title":"association","text":"<p>(NL: verband)</p> <p>In the context of bivariate analysis, we speak of an association (or relation) between two variables if the values of one variable systematically change as the values of the other variable change. In other words, if you know the value of one variable, you can - to a certain extent - predict the value of the other variable.</p> <p>Usually we assume that one variable exerts a certain influence on the other. The variable that we suspect exerts the influence is called the independent variable. The variable that we suspect is influenced is called the dependent variable.</p> <p>Researchers must be careful that, if an association is found between two variables, this does not necessarily imply a causal relationship. The \"influence\" can go in the opposite direction, or both variables can be influenced by a third, unexamined, variable. Demonstrating a causal relationship requires a specific research design, in which the researcher excludes the influence of all other variables.</p>"},{"location":"en/bar-chart/","title":"bar chart","text":"<p>(NL: staafdiagram)</p> <p>A bar chart is a chart type that displays the frequencies of the values of a qualitative variable using rectangles. The height of a bar represents the frequency of the corresponding value.</p> <p>With a simple bar chart, you can visualize a single variable. To visualize two variables at the same time, you can use a clustered bar chart, a stacked bar chart or a mosaic plot.</p>"},{"location":"en/bar-chart/#clustered-bar-chart","title":"Clustered bar chart","text":"<p>In a clustered bar chart, multiple bar charts are combined. The bar charts are grouped per value of the dependent variable, which is displayed on the X-axis. Distinction between the independent variable is usually made by color or shading of the bars.</p> <p>Example:</p> <p></p> <ul> <li>The colours denote the values of the independent variable <code>Gender</code>. Blue bars represent the values <code>Female</code> and orange bars represent the values <code>Male</code>.</li> <li>The dependent variable <code>Survey</code> is displayed on the X-axis. Bars are grouped per value of <code>Survey</code>.</li> <li>If the \"shape\" of the bars in the different colors are similar, this is an indication that there is no relation between the variables. If there are large differences (e.g. a different mode, values that are not present in one of the groups, etc.), this is an indication that there is a relation between the variables.</li> <li>When there is a large difference between the number of observations for each value of the independent variable, or when the number of different values of the independent variable is large, it is hard to determine whether there is a relation. That's in fact the case for this plot: there are considerably less observations for <code>Female</code> than for <code>Male</code>. To solve this problem, you can use a stacked bar chart.</li> </ul>"},{"location":"en/bar-chart/#stacked-bar-chart","title":"Stacked bar chart","text":"<p>In a stacked bar chart, bars aren't clustered, but stacked on top of each other. Additionaly, it's useful to normalise the totals, so it's easier to compare the relative frequencies of the different values of the dependent variable.</p> <p>Example:</p> <p></p> <ul> <li>The independent variable <code>Gender</code> is displayed on the Y-axis</li> <li>The dependent variable <code>Survey</code> is displayed on the X axis, each value is represented by a color.</li> <li>To make the differences in the proportions between the two groups clearer, the total of each group has been normalized to 100%. The height of the colored areas therefore represents the ratio, not the absolute number of observations.</li> <li>If the boundaries between the color planes are match up between the bars, then this is an indication that there is no relationship between the two variables. If there are large differences, then this is an indication that there is a relationship between the two variables.<ul> <li>In this diagram we see that the boundaries between the color areas are not quite at the same height, but broadly speaking similar proportions reappear. This is an indication that there is no or only a weak relationship between the two variables.</li> </ul> </li> <li>Note that you can also display a bar chart vertically, but then you must ensure that it is plotted sufficiently large. Otherwise it is difficult to estimate the differences in the proportions.</li> <li>With a bar chart we do not see that there are more observations for <code>Male</code> than for <code>Female</code>. A mosaicchart can solve this problem. It retains the properties of a bar chart, but also shows the number of observations of the independent variable.</li> </ul>"},{"location":"en/boxplot/","title":"boxplot","text":"<p>(NL: boxplot)</p> <p>TODO</p>"},{"location":"en/central-limit-theorem/","title":"central limit theorem","text":"<p>(NL: centrale limietstelling)</p> <p>The central limit theorem says that the probability distribution of the sample mean will resemble the normal distribution as the sample size increases.</p> <p>Or, more specifically, if you take a sufficiently large (\\(n &gt;30\\)) random sample from a population with expected value \\(\\mu\\) and standard deviation \\(\\sigma\\), then the sample mean \\(\\bar{x}\\) will have a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\frac{\\sigma}{\\sqrt{n}}\\). This holds regardless of the distribution of the population!</p> <p>The central limit theorem is an important basis for many statistical methods, such as confidence intervals and hypothesis tests. It dictates the conditions under which we can generalize a result from a sample (to a certain extent) to the population.</p>"},{"location":"en/chi-squared-distribution/","title":"chi-squared distribution","text":"<p>(NL: chi-kwadraatverdeling)</p> <p>The \\(\\chi^2\\) distribution is a probability distribution used in statistics. The distribution depends on a parameter, namely the number of degrees of freedom. The \\(\\chi^2\\) distribution is often used in the context of the \\(\\chi^2\\) test.</p> <p></p>"},{"location":"en/chi-squared-test/","title":"chi-squared test","text":"<p>(NL: chi-kwadraattoets)</p>"},{"location":"en/chi-squared-test/#test-for-independence","title":"test for independence","text":"<p>The \\(\\chi^2\\) test for independence is used to determine whether there is an association between two qualitative variables. The null hypothesis is that there is no relationship between the variables (in other words, they are independent). The alternative hypothesis is that there is a relationship.</p> <p>The test is performed on a contingency table, which shows the frequencies of the combinations of the two variables. The value indicates how far the observed frequencies deviate from the expected frequencies if the two variables were independent of each other.</p> <p>In a contingency table with independent variables, the probability distribution of the \\(\\chi^2\\) value is known and given by the so-called \\(\\chi^2\\) distribution with \\((r-1)(c-1)\\) degrees of freedom, where \\(r\\) is the number of rows and \\(c\\) is the number of columns in the contingency table. This allows us to determine the significance of the deviation.</p> <p>The testing procedure is as follows:</p> <ul> <li>Step 1: Formulate the null hypothesis \\(H_0\\) and the alternative hypothesis \\(H_1\\).<ul> <li>\\(H_0\\): there is no relationship between the variables</li> <li>\\(H_1\\): there is a relationship between the variables</li> </ul> </li> <li>Step 2: Choose the significance level \\(\\alpha\\).</li> <li>Step 3: Calculate the test statistic, in this case the \\(\\chi^2\\) value based on the observations in the contingency table (\\(\\chi^2_{\\text{obs}}\\)).</li> <li>Step 4: Either:<ul> <li>Determine the critical value \\(g\\) such that \\(P(\\chi^2 &gt; g) = \\alpha\\).</li> <li>Determine the p-value \\(p = P(\\chi^2 &gt; \\chi^2_{\\text{obs}})\\).</li> </ul> </li> <li>Step 5: Make a decision:<ul> <li>Accept \\(H_0\\) if \\(p &gt; \\alpha\\) or \\(\\chi^2_{\\text{obs}} &lt; g\\).</li> <li>Reject \\(H_0\\) if \\(p \\leq \\alpha\\) or \\(\\chi^2_{\\text{obs}} \\geq g\\).</li> </ul> </li> </ul> <p>Note that the \\(\\chi^2\\) test is always one-sided.</p>"},{"location":"en/chi-squared-test/#goodness-of-fit-test","title":"goodness-of-fit test","text":"<p>The \\(\\chi^2\\) goodness-of-fit test is used to determine whether the distribution of a sample matches a particular distribution. One situation where this is applicable is when you have taken a sample from a population of which you know the distribution, and you want to determine whether the sample is representative of the population (i.e., whether the sample distribution matches the population distribution).</p> <p>The null hypothesis is that the sample distribution matches the given distribution. The alternative hypothesis is that the sample distribution does not match the given distribution.</p> <p>To perform the test, you need the frequency table of the sample (denoted \\(o_i\\)), and the expected frequencies (denoted \\(\\pi_i\\)) in the population. The expected values \\(e_i\\) can then be calculated with \\(e_i = n \\cdot \\pi_i\\), where \\(n = \\sum_{i=1}^k o_i\\) is the total number of observations in the sample and \\(k\\) is the number of categories in the distribution. The probability distribution of \\(\\chi^2\\) is in this case given by the \\(\\chi^2\\) distribution with \\(k-1\\) degrees of freedom.</p> <p>The calculation of \\(\\chi^2\\) and the testing procedure proceed analogously to the independence test.</p>"},{"location":"en/chi-squared/","title":"chi squared","text":"<p>(NL: chi-kwadraat)</p> <p>Chi-squared (Noted \\(\\chi^2\\), with the Greek letter \"chi\") is a statistic used to determine whether there is an association between two qualitative variables.</p> <p>The value is calculated on a contingency table, in which the frequencies of the combinations of the two variables are displayed. The value indicates how far observed frequencies deviate from expected frequencies if the two variables were independent of each other.</p> \\[\\chi^2 = \\sum \\frac{(o_i - e_i)^2}{e_i}\\] <p>where:</p> <ul> <li>\\(\\chi^2\\) = chi-squared value</li> <li>\\(o_i\\) = observed frequency of combination \\(i\\)</li> <li>\\(e_i\\) = expected frequency of combination \\(i\\)</li> </ul> <p>If the observed values completely match the expected values, then \\(\\chi^2 = 0\\). The larger the value, the greater the deviation between the observed and expected values. The \\(\\chi^2\\) distribution is used to determine the significance of the deviation.</p> <p>Chi-squared is used in \\(\\chi^2\\) tests to determine whether there is an association between two qualitative variables (independence test), or to determine whether the distribution of a qualitative variable matches a certain distribution (goodness-of-fit test).</p>"},{"location":"en/cochrans-rules/","title":"Cochran's rules","text":"<p>(NL: Cochran's regels)</p> <p>Cochran's rules are a set of rules to determine whether the results of a chi-square test are reliable. More specifically, there should be \"sufficient\" observations in each category of a contingency table or frequency table to apply the chi-square test. Cochran's rules determine how much \"sufficient\" exactly is.</p> <p>The rules are typically formulated as follows:</p> <ol> <li>Each cell in the table should have an expected frequency of at least 1.</li> <li>In at least 80% of the cells, the expected frequency should be at least 5 (or at most 20% of the cells may have an expected frequency of less than 5).</li> </ol> <p>The rules are named after the American statistician William G. Cochran to whom they are attributed, based on his work in the 1950s (Cochran, 1952; 1954, p.420). For an extensive discussion of Cochran's rules, see Kroonenberg &amp; Verbeek (2018).</p>"},{"location":"en/cochrans-rules/#references","title":"References","text":"<p>Cochran, W. G. (1952). The \u03c72 test of goodness of fit. The Annals of Mathematical Statistics, 23(3), 315-345. https://doi.org/10.1214/aoms/1177729380</p> <p>Cochran, W. G. (1954). Some Methods for Strengthening the Common \u03c7 2 Tests. Biometrics, 10(4), 417-451. https://doi.org/10.2307/3001616</p> <p>Kroonenberg, P. M., &amp; Verbeek, A. (2018). The Tale of Cochran\u2019s Rule: My Contingency Table has so Many Expected Values Smaller than 5, What Am I to Do? The American Statistician, 72(2), 175\u2013183. https://doi.org/10.1080/00031305.2017.1286260</p>"},{"location":"en/cohens-d/","title":"Cohen's d","text":"<p>(NL: Cohen's d)</p> <p>Cohen's \\(d\\) is a measure for the strength of the difference between two groups. It is calculated as the difference between the means of the two groups, divided by the standard deviation of the sample.</p> \\[d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s}\\] <p>with \\(s\\) a point estimate for the standard deviation of the population, based on the observations in both groups:</p> \\[s = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\\] <p>Here, \\(\\bar{x}_1\\) and \\(\\bar{x}_2\\) are the means of the two groups, \\(s_1\\) and \\(s_2\\) are the standard deviations of the two groups, \\(n_1\\) and \\(n_2\\) are the sample sizes of the two groups.</p> <p>The interpretation of (the absolute value of) Cohen's \\(d\\) is as follows:</p> \\(d\\) Interpretation 0.01 Very small difference 0.20 Small difference 0.50 Medium difference 0.80 Large difference 1.20 Very large difference 2.00 Huge difference <p>However, this interpretation is not absolute. The interpretation of a certain value of \\(d\\) depends on the context and the research question.</p> <p>In education sciences, Cohen's \\(d\\) is often used to assess whether a certain intervention in education has a sufficiently large effect on students' learning outcomes. John Hattie has compiled a list of effect sizes for different educational interventions, which he updates regularly (Waack, 2018). One of his contributions to educational sciences is the awareness that some interventions are extremely expensive and/or time-consuming, but have only a very small effect on students' learning outcomes. The overview also shows that some \"trendy\" educational methods such as discovery learning actually have little effect on learning outcomes. To be meaningful, the effect size of an intervention should be at least 0.40. An effect size of 1 would be a very large effect and would mean that the same material could be covered in half the time.</p>"},{"location":"en/cohens-d/#references","title":"References","text":"<p>Waack, S. (2018) Hattie Ranking: 252 Influences And Effect Sizes Related To Student Achievement. Retrieved 2025-03-19 from https://visible-learning.org/hattie-ranking-influences-effect-sizes-learning-achievement/</p>"},{"location":"en/confidence-interval/","title":"confidence interval","text":"<p>(NL: betrouwbaarheidsinterval)</p> <p>A confidence interval is an interval that is calculated from a sample as an estimate for an unknown population parameter. The interval indicates, with a certain (chosen) confidence, within which bounds the population parameter lies.</p>"},{"location":"en/confidence-level/","title":"confidence level","text":"<p>(NL: betrouwbaarheidsniveau)</p> <p>The confidence level \\(1-\\alpha\\) is the theoretical probability that a confidence interval contains the unknown population parameter.</p> <p>The confidence level is related to the significance level \\(\\alpha\\) of a hypothesis test.</p>"},{"location":"en/contingency-table/","title":"contingency table","text":"<p>(NL: kruistabel)</p> <p>A contingency table (also: crosstab) is a table that summarizes the frequencies of the combination of the values of two qualitative variables.</p> <p>The convention is to put the values of the independent variable in the columns and the values of the dependent variable in the rows.</p> <p>A contingency table can be completed with the sum of each row or column. These are called marginals or marginal totals.</p>"},{"location":"en/contingency-table/#example","title":"Example","text":"Female Male Strongly disagree 0 4 Disagree 17 45 Neutral 23 91 Agree 12 53 Strongly agree 0 5 <ul> <li>The values of the independent variable <code>Gender</code> are in the columns: <code>Female</code> and <code>Male</code>.</li> <li>The values of the dependent variable <code>Survey</code> are in the rows: <code>Strongly disagree</code>, <code>Disagree</code>, <code>Neutral</code>, <code>Agree</code> and <code>Strongly agree</code>.</li> <li>The numbers in the cells are the observed frequencies of the combinations of the values of the two variables.</li> </ul> <p>With added marginals:</p> Female Male Total Strongly disagree 0 4 4 Disagree 17 45 62 Neutral 23 91 114 Agree 12 53 65 Strongly agree 0 5 5 Total 52 198 250 <ul> <li>The total number of observations \\(n = 250\\).</li> </ul>"},{"location":"en/correlation/","title":"correlation","text":"<p>(NL: correlatie)</p> <p>In the broadest sense, correlation is any relationship between two stochastic variables. However, usually one means the extent to which two variables show a linear relationship.</p> <p>There are several ways to measure the correlation between two variables. The most well-known is the Pearson correlation coefficient.</p>"},{"location":"en/correlation/#covariance","title":"covariance","text":"<p>Covariance is a measure that indicates whether a relationship between two variables is positive (increasing) or negative (decreasing). The sample covariance between two variables \\(X\\) and \\(Y\\) is defined as:</p> \\[\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\\] <p>If the covariance is positive, this means that the variables increase together. If the covariance is negative, this means that the variables evolve in opposite directions. If the covariance is zero, or close to 0, this means that there is no clear increasing or decreasing relationship between the variables.</p> <p>Note that:</p> <ul> <li> <p>there is also a population covariance, with \\(n\\) in the denominator instead of \\(n-1\\).</p> </li> <li> <p>the covariance is sensitive to the unit of measurement of the variables. If you convert observations to another unit of measurement, the covariance will change!</p> </li> <li> <p>the covariance is a generalization of the concept of variance. The variance of a variable is the covariance of that variable with itself.</p> </li> </ul>"},{"location":"en/correlation/#correlation-coefficient","title":"correlation coefficient","text":"<p>Pearson's product-moment correlation coefficient is a measure of the strength and direction of a linear relationship between two quantitative variables.</p> <p>The correlation coefficient of a sample is defined as:</p> \\[R = \\frac{\\text{Cov(X,Y)}}{s_Xs_Y} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\\] <p>The value of \\(R\\) lies between -1 and 1. A value of 1 means a perfect positive linear relationship, i.e. all observations lie on one increasing straight line. A value of -1 means a perfect negative linear relationship, so that the observations lie on a decreasing straight line. A value of 0 means that there is no linear relationship.</p> <p>Note that:</p> <ul> <li> <p>The correlation coefficient is not sensitive to the unit of measurement of the variables. If you convert observations to another unit of measurement, the correlation coefficient will not change.</p> </li> <li> <p>The correlation coefficient does not say anything about the degree of increase, only about the direction. The slope of a regression line that best fits the data will tell you more about that.</p> </li> <li> <p>The correlation coefficient itself does not always say much. A correlation coefficient of 0.8 seems to indicate a strong linear relationship, but that is not always the case! It remains important to visualize and interpret the data. Look, for example, at Anscombe's quartet for an illustration of this.</p> </li> <li> <p>Correlation is not causation! A high correlation coefficient does not necessarily mean that there is a causal relationship between the variables. It may also be that both variables are influenced by a third variable.</p> </li> </ul>"},{"location":"en/correlation/#coefficient-of-determination","title":"coefficient of determination","text":"<p>The coefficient of determination expresses which part of the variance of the dependent variable is explained by the independent variable.</p> <p>The coefficient of determination is equal to the square of the correlation coefficient \\(R^2\\) and is therefore a value between 0 and 1. For example, if \\(R^2 = 0.35\\), we say that 35% of the variance in the dependent variable is explained by the independent variable.</p>"},{"location":"en/correlation/#interpretation-of-r-and-r2","title":"interpretation of \\(R\\) and \\(R^2\\)","text":"\\(R\\) \\(R^2\\) Interpretation 0.00 0.00 No relationship 0.10 0.01 Very weak relationship 0.30 0.09 Weak relationship 0.50 0.25 Average relationship 0.70 0.49 Strong relationship 0.90 0.81 Very strong relationship 1.00 1.00 Perfect relationship"},{"location":"en/cramers-v/","title":"Cramer's V","text":"<p>(NL: Cramer's V)</p> <p>Cram\u00e9r's V is a measure of association between two qualitative variables. It ranges from 0 to 1, where 0 means no association and 1 means perfect association. It is based on the chi-square statistic and is defined as</p> \\[V = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\\] <p>where \\(\\chi^2\\) is the chi-squared statistic, \\(n\\) is the number of observations, and \\(k\\) is the number of categories in the contingency table.</p>"},{"location":"en/critical-region/","title":"critical region","text":"<p>(NL: kritieke gebied)</p> <p>In the context of hypothesis tests, the critical region (also: rejection region) is the set of all possible values for the test statistic for which we will reject the null hypothesis.</p> <p>Or, in other words, this is the set of all values for the test statistic for which the p-value is less than the significance level.</p> <p>The values for which we do not reject the null hypothesis from the region of acceptance.</p>"},{"location":"en/critical-value/","title":"critical value","text":"<p>(NL: kritieke grenswaarde)</p> <p>In the context of hypothesis tests, the critical value is the value for the test statistic that lies on the boundary between the critical region and the region of acceptance.</p> <p>More specifically, this is a value for which the p-value \\(p\\) is equal to the significance level \\(\\alpha\\).</p>"},{"location":"en/effect-size/","title":"effect size","text":"<p>(NL: effectgrootte)</p> <p>The effect size is a measure that expresses the strength of an association between two variables.</p> <p>Depending on the context, and more specifically on the measurement levels of the variables, there are different methods to define an effect size.</p> <ul> <li> <p>Cramer's V is a measure for the strength of the association between two qualitative variables.</p> </li> <li> <p>Cohen's d is a measure for the difference (of the mean) between two groups.</p> </li> <li> <p>Pearson's correlation coefficient is a measure for the strength of a linear association between two quantitative variables.</p> </li> </ul> <p>In addition to these, there are dozens of definitions of effect sizes, each with their own scope and interpretation.</p> <p>Effect sizes are complementary to hypothesis testing. A hypothesis test determines whether an association is statistically significant, while an effect size indicates how strong that association is.</p>"},{"location":"en/frequency/","title":"frequency","text":"<p>(NL: frequentie)</p> <p>The frequency of a value of a variable in a data set or sample is the number of times that value occurs.</p> <p>We distinguish on the one hand the absolute frequency (= the actual number) and on the other hand the relative frequency (= what percentage of the total number of observations takes this value, as a fraction between 0 and 1).</p> <p>The frequencies of each unique value occurring in the sample are summarized in a frequency table. A frequency table that summarizes the frequencies of the combination of the values of two variables is also called a contingency table, or crosstab.</p>"},{"location":"en/greek-alphabet/","title":"Greek alphabet","text":"<p>(NL: Het Griekse alfabet)</p> <p>Greek letters are regularly used in statistics (and mathematics in general). Since most students may not have learned Greek, we provide the letters of the Greek alphabet here.</p> <p>In the left column we give the capital and small letter (and for some letters an alternative notation). The middle column is the name of the Greek letter and the right column is the equivalent in the Latin alphabet.</p> Grieks Naam Equivalent \u0391, \u03b1 alpha a \u0392, \u03b2 beta b \u0393, \u03b3 gamma g \u0394, \u03b4 delta d \u0395, \u03b5 epsilon e \u0396, \u03b6 zeta dz \u0397, \u03b7 eta ei \u0398, \u03b8 theta th \u0399, \u03b9 iota i \u039a, \u03ba kappa k \u039b, \u03bb lambda l \u039c, \u03bc mu m \u039d, \u03bd nu n \u039e, \u03be xi x, ks \u039f, \u03bf omikron o (\"little o\") \u03a0, \u03c0 pi p \u03a1, \u03c1 rho r \u03a3, \u03c3/\u03c2 sigma s \u03a4, \u03c4 tau t \u03a5, \u03c5 upsilon u \u03a6, \u03c6 phi f \u03a7, \u03c7 chi ch \u03a8, \u03c8 psi ps \u03a9, \u03c9 omega aw (\"big o\")"},{"location":"en/histogram/","title":"histogram","text":"<p>(NL: histogram)</p> <p>TODO</p>"},{"location":"en/hypothesis-test/","title":"hypothesis test","text":"<p>(NL: hypothesetoets)</p> <p>A statistical hypothesis test is a procedure to determine whether a statement or conjecture about a sampled population is correct.</p> <p>The procedure consists of the following steps:</p> <ol> <li>Formulate the null hypothesis \\(H_0\\) and the alternative hypothesis \\(H_1\\).</li> <li>Choose a significance level \\(\\alpha\\).</li> <li>Calculate the test statistic from the sample</li> <li>Determine:<ul> <li>either the p-value \\(p\\)</li> <li>or the critical region</li> </ul> </li> <li>Draw a conclusion based on the p-value or the critical area.</li> </ol> <p>A statistical test starts from the assumption that the null hypothesis is true and builds an argument based on that. As with a proof by contradiction, we may then run into a contradiction. In that case, the null hypothesis is rejected and the alternative hypothesis is accepted.</p> <p>Drawing a conclusion based on the probability of exceedance is done as follows:</p> <ul> <li>If \\(p \\leq \\alpha\\) then the null hypothesis is rejected and the alternative hypothesis is accepted.</li> <li>If \\(p &gt; \\alpha\\) then the null hypothesis is not rejected.</li> </ul> <p>Or, based on the critical area:</p> <ul> <li>If the test statistic is within the critical region, then the null hypothesis is rejected and the alternative hypothesis is accepted.</li> <li>If the test statistic is not in the critical but in the acceptance region, then the null hypothesis is not rejected.</li> </ul> <p>Note that these two methods are equivalent, so in practice you should not run both. In the scientific literature, the probability of exceedance is usually used and also reported explicitly.</p> <p>Statistical tests discussed in this course:</p> <ul> <li>the z-key</li> <li>the t-test</li> <li>the two-sample t-test</li> <li>the chi-square goodness-of-fit test</li> <li>the chi-square test for independence</li> </ul>"},{"location":"en/interquartile-range/","title":"interquartile range","text":"<p>(NL: interkwartielafstand (IQR))</p> <p>The interquartile range (IQR) of a sample or population is calculated as:</p> \\[ IQR = | Q_3 - Q_1 | \\] <p>With \\(Q_3\\) the third quartile and \\(Q_1\\) the first quartile.</p> <p>Between \\(Q_1\\) and \\(Q_3\\) you will find 50% of the observations in the sample.</p> <p>The interquartile range is a measure of dispersion for quantitative variables. It is less sensitive to outliers than the standard deviation and is therefore better suited than the standard deviation for variables that are not normally distributed.</p>"},{"location":"en/kdeplot/","title":"kernel density estimation plot","text":"<p>(NL: kerndichtheidsschattingsdiagram)</p> <p>TODO</p>"},{"location":"en/level-of-measurement/","title":"level of measurement","text":"<p>(NL: meetniveau)</p> <p>By the measurement level of a variable we mean the variable type. In statistics we distinguish the following levels:</p> <ul> <li>Qualitative (also: categorical, discrete) variables<ul> <li>Nominal</li> <li>Ordinal</li> </ul> </li> <li>Quantitative (also: continuous) variables<ul> <li>interval</li> <li>Ratios</li> </ul> </li> </ul> <p>The levels of measurement of variables determine the most suitable statistical techniques for examining and interpreting them.</p>"},{"location":"en/level-of-measurement/#qualitative-variables","title":"Qualitative variables","text":"<p>What is typical about qualitative variables is that there are usually a limited number of possible values and these values are not necessarily numerical.</p>"},{"location":"en/level-of-measurement/#nominal-scale","title":"Nominal scale","text":"<p>Variables whose values we can only enumerate or name, without any logical or inherent order between them, are called nominal.</p> <p>Examples of nominal variables:</p> <ul> <li>gender (male, female, non-binary, ...)</li> <li>political party</li> <li>country in which you live</li> </ul> <p>Note that in some datasets the value of a nominal variable can be represented by numbers (eg 0 = died, 1 = survived). However, that does not change the level of measurement.</p>"},{"location":"en/level-of-measurement/#ordinal-scale","title":"Ordinal scale","text":"<p>Ordinal variables are qualitative variables where there is an inherent order between the values.</p> <p>Examples of ordinal variables:</p> <ul> <li>Education level (pre-school, primary, lower secondary, higher secondary, higher vocational education, bachelor, master, doctorate)</li> <li>Likert scale (strongly disagree, disagree, no opinion, agree, strongly agree)</li> <li>Assessment scale (unsatisfactory, satisfactory, with distinction, with great distinction, with greatest distinction)</li> </ul>"},{"location":"en/level-of-measurement/#quantitative-variables","title":"Quantitative variables","text":"<p>Quantitative variables express a quantity and are always numeric. You must also always indicate in which unit of measurement this numerical value is expressed.</p> <p>It is quite possible that each observation is a unique value within the sample, or at least you expect many different values.</p>"},{"location":"en/level-of-measurement/#interval-scale","title":"Interval scale","text":"<p>An interval-scale quantity has no fixed zero point, but rather one is interested in differences between two values.</p> <p>A typical example of an interval scale is the temperature in \u02daC. The difference between 10\u02daC and 20\u02daC is the same as between 13\u02daC and 23\u02daC.</p> <p>Because there is no fixed zero point, you cannot calculate with ratios. It is therefore not the case that a temperature of 20\u02daC is double that of 10\u02daC. If you were to convert both values to \u02daF (namely 50\u02daF and 68\u02daF respectively), the ratio would no longer be correct.</p> <p>Examples:</p> <ul> <li>Temperature (\u02daC, \u02daF)</li> <li>Date, time, timestamp (Unix time, Gregorian calendar, Islamic calendar, ...)</li> </ul>"},{"location":"en/level-of-measurement/#ratio-scale","title":"Ratio scale","text":"<p>With a ratio scale you also have a numerical value and a unit of measurement, but there is also a clear and fixed zero point. As a result, you can also calculate with proportions (Latin and English: ratio).</p> <p>Examples are:</p> <ul> <li>Mass (g, kg, ...)</li> <li>Distance (mm, cm, m, km, ...)</li> <li>Surface (m\u00b2, ca, a, ha, ...)</li> <li>Energy (J)</li> <li>Age (y)</li> <li>Duration (ms, s, min, h, ...)</li> <li>Temperature (\u02daK)</li> </ul> <p>A distance between two objects cannot be negative, so there is clearly an absolute zero point. If the distance between two objects is 100cm and between two others is 150cm, then that second distance is 50% greater.</p> <p>Temperature in Kelvin is a ratio scale because 0\u02daK is absolute zero. If the temperature expressed in Kelvin doubles, the energy present also doubles.</p>"},{"location":"en/marginals/","title":"marginals","text":"<p>(NL: marginalen)</p> <p>Marginals or marginal totals are the totals of the rows or columns of a contingency table.</p>"},{"location":"en/mean/","title":"mean","text":"<p>(NL: gemiddelde)</p> <p>The mean is a measure of central tendency that is especially suited for quantitative variables.</p> <p>The mean is often used in comnbination with the standard deviation to describe the characteristics of a sample.</p>"},{"location":"en/mean/#sample-mean","title":"sample mean","text":"<p>The (arithmetic) mean \\(\\overline{x}\\) of a sample \\(X = \\{x_1, \\ldots, x_n\\}\\) of size \\(n\\) is</p> \\[\\overline{x} = \\frac{1}{n} \\sum_{x=1}^{n} x_i\\]"},{"location":"en/mean/#population-mean","title":"population mean","text":"<p>The mean of a population is notated with the Greek letter mu: \\(\\mu\\). The calculation is equivalent with the sample mean.</p>"},{"location":"en/measure-of-central-tendency/","title":"measure of central tendency, mean","text":"<p>(NL: centrummaat)</p> <p>A measure of central tendency (or mean) for a variable is a value that is considered \"typical\" for that group. There are several ways to calculate a measure of central tendency. Only a few are listed below.</p> <p>Depending on the level of measurement, specific measures are ideally suited:</p> <ul> <li>Qualitative variables: mode</li> <li>Quantitative variables: arithmetic mean, median</li> </ul> <p>In addition to a measure of center, one typically also uses a measure of dispersion to express the variability of observations for that variable.</p>"},{"location":"en/measure-of-dispersion/","title":"measure of dispersion","text":"<p>(NL: spreidingsmaat)</p> <p>A measure of dispersion expresses the extent to which values in a sample or population differ from each other.</p> <p>There are several ways to determine a measure of dispersion, we will use only a few of them in this course. The measures of dispersion discussed are only suitable for quantitative variables.</p> <ul> <li>variance and standard deviation</li> <li>interquartile range and range</li> </ul> <p>Together with a measure of central tendency, a measure of dispersion forms a way of expressing the characteristics of observations for a variable.</p>"},{"location":"en/median/","title":"median","text":"<p>(NL: mediaan)</p> <p>The median of a sample or population is the value that separates the lower half of the values from the higher half.</p> <p>You can determine the median by sorting the values and taking the middle value (if the number is odd), or the average of the two middle values (if the number is even).</p> <p>The median can be used with quantitative variables or ordinal.</p> <p>The measure of dispersion that is often used together with this measure of center is the interquartile range.</p>"},{"location":"en/mode/","title":"mode","text":"<p>(NL: modus)</p> <p>The mode of a (qualitative) variable is the value that occurs most frequently in the sample.</p> <p>In principle you can also calculate the mode of a quantitative variable, but that is usually not useful.</p>"},{"location":"en/mosaic-plot/","title":"mosaic plot","text":"<p>(NL: moza\u00efekdiagram)</p> <p>A mosaic plot is a graphical representation of a contingency table that shows the relative frequencies of the different combinations of values of two (or more) categorical variables.</p> <p>The width of the rectangles in the plot is proportional to the relative frequency of the values of the first variable, and the height is proportional to the relative frequency of the values of the second variable. The area of each rectangle is thus proportional to the relative frequency of the combination of values of both variables.</p> <p></p> <p>The independent variable is typically displayed on the x-axis and the dependent variable on the y-axis.</p>"},{"location":"en/normal-distribution/","title":"normal distribution","text":"<p>(NL: normale verdeling)</p> <p>The normal distribution is a continuous probability distribution with two parameters: the expected value \\(\\mu\\) and the standard deviation \\(\\sigma\\).</p> <p>The normal distribution with expected value \\(\\mu = 0\\) and standard deviation \\(\\sigma = 1\\) is called the standard normal distribution.</p> <p>If a stochastic variable \\(X\\) has a normal distribution with expectation value \\(\\mu\\) and standard deviation \\(\\sigma\\), then we write \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\).</p> <p>The probability density function looks like this:</p> <p></p> <p>The cumulative probability density function (or left tail probability) looks like this:</p> <p></p>"},{"location":"en/notation/","title":"notation","text":"<p>(NL: notatie)</p>"},{"location":"en/notation/#sample-and-population","title":"Sample and population","text":"Sample Population Size \\(n\\) \\(N\\) Mean \\(\\overline{x}\\) \\(\\mu\\) Variance \\(s^2\\) \\(\\sigma^2\\) Standard deviation \\(s\\) \\(\\sigma\\)"},{"location":"en/notation/#probability-theory","title":"Probability theory","text":"<p>See also probability</p> Symbol Interpretation \\(\\Omega\\) universe \\(A, B, \\ldots\\) events (with \\(A \\subset \\Omega\\), \\(B \\subset \\Omega\\), etc.) \\(P(A)\\) the probability of event \\(A\\) (with \\(0 \\leq P(A) \\leq 1\\)) \\(P(A|B)\\) the probability of \\(A\\) if \\(B\\) occurs"},{"location":"en/notation/#the-normal-distribution","title":"The normal distribution","text":"<p>If a  \\(X\\) has a normal distribution with expectation value \\(\\mu\\) and standard deviation \\(\\sigma\\), then we write \\(X \\sim \\mathcal{N}(\\mu, \\ sigma)\\).</p> <p>We write the standard normal distribution as \\(Z \\sim \\mathcal{N}(0, 1)\\).</p> <p>We write the probability distribution of the sample mean as \\(M \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\\).</p> <ul> <li>\\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\)<ul> <li>The stochastic variable \\(X\\) has a normal distribution with expected value \\(\\mu\\) and standard deviation \\(\\sigma\\)</li> </ul> </li> <li>\\(Z \\sim \\mathcal{N}(0, 1)\\)<ul> <li>The standaad normal distribution.</li> </ul> </li> <li>\\(M \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\\)<ul> <li>The probability distribution of the sample mean (see the central limit theorem).</li> </ul> </li> </ul>"},{"location":"en/notation/#statistic-hypothesis-tests","title":"Statistic hypothesis tests","text":"<ul> <li>\\(H_0\\) - the null hypothesis</li> <li>\\(H_1\\) - the alternative hypothesis</li> <li>\\(\\alpha\\) - the significance level</li> </ul>"},{"location":"en/null-hypothesis/","title":"null hypothesis","text":"<p>(NL: nulhypothese)</p> <p>In the context of a statistical hypothesis test, the null hypothesis (often written as \\(H_0\\)) is an assumption about a population parameter that we want to test.</p> <p>The null hypothesis usually represents the assumption that there is no significant difference between the population parameter and a given value, or that there is no relationship between two variables.</p> <p>The procedure of the test is based on the assumption that the null hypothesis is true. If we then encounter a contradiction, the null hypothesis is rejected and the alternative hypothesis is accepted.</p>"},{"location":"en/observation/","title":"observation","text":"<p>(NL: waarneming)</p> <p>An observation is an individual measurement or value within a sample or random variable.</p>"},{"location":"en/p-value/","title":"p-value","text":"<p>(NL: overschrijdingskans)</p> <p>The p-value is the probability that the value of the test statistic (or one that is at least as extreme) can be obtained if the null hypothesis is true.</p> <p>When the p-value is less than the significance level that was chosen in advance, or \\(p \\leq \\alpha\\), then the null hypothesis is rejected and the alternative hypothesis is accepted. If \\(p &gt; \\alpha\\) then the null hypothesis is not rejected.</p>"},{"location":"en/percentile/","title":"percentile","text":"<p>(NL: percentiel)</p> <p>A percentile of an ordered series of observations is one of basically 99 points that divides the series into 100 equally sized parts. The \\(k\\)th percentile, then, is a number where \\(k\\)% of the observations are smaller and \\((100-k)\\)% are greater than that number.</p>"},{"location":"en/percentile/#quartile","title":"quartile","text":"<p>The quartiles are formed from five specific percentiles that divide the series into 4 equally sized parts:</p> <ul> <li>\\(\\min\\), the minimum, or percentile 0</li> <li>\\(Q_1\\), the first quartile or percentile 25</li> <li>\\(Q_2\\), the median, or percentile 50</li> <li>\\(Q_3\\), the third quartile or percentile 75</li> <li>\\(\\max\\), the maximum, or percentile 100</li> </ul> <p>The difference between the largest and smallest value is called range, and between the third and first quartiles is called interquartile range.</p>"},{"location":"en/point-estimate/","title":"point estimate","text":"<p>(NL: puntschatter)</p> <p>A point estimate is a value calculated from a sample that tries to approximate an unknown population parameter as well as possible.</p> <p>The formula for the sample standard deviation \\(s\\) is a point estimate for the (unknown) population standard deviation \\(\\sigma\\).</p> <p>An estimator is sometimes denoted as \\(\\hat{\\theta}\\), where \\(\\theta\\) is an unknown population parameter.</p> <p>See also: confidence interval</p>"},{"location":"en/population/","title":"population","text":"<p>(NL: populatie)</p> <p>A population is a group of objects that is being researched. In many cases, a population is so large that it is infeasible to conduct the research on each individual. Therefore, a sample is drawn.</p>"},{"location":"en/probability-distribution/","title":"probability distribution","text":"<p>(NL: kansverdeling)</p> <p>The probability distribution of a stochastic variable \\(X\\) is a mathematical function that gives the probability that a certain outcome for \\(X\\) can occur.</p> <p>A distinction is made between discrete and continuous distributions. The probability distribution of a discrete variable is described by a probability mass function, that of a continuous variable by a probability density function.</p>"},{"location":"en/probability-distribution/#probability-mass-function","title":"Probability mass function","text":"<p>(NL: kansfunctie)</p> <p>With a discrete random variable, you can enumerate the probability \\(P(X = x)\\) for every possible outcome \\(x\\).</p> <p>Example: the total number of eyes thrown with two dice is a discrete random variable with values \\(2, 3, \\ldots, 12\\). The probability mass function of this variable can be summarized as follows:</p> \\(x\\) 2 3 4 5 6 7 8 9 10 11 12 \\(P(X = x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 <p>Or, in a more compact form:</p> \\[P(X = x) = \\frac{min(x-1, 13-x)}{36}\\] <p>This function satisfies the axioms of probability theory:</p> <ul> <li>\\(\\forall x: 0 \\leq P(X = x) \\leq 1\\)</li> <li>\\(\\sum_x P(X = x) = 1\\)</li> <li>The sum rule also works, e.g. the probability that you throw an even number is \\(P(X = 2) + P(X = 4) + \\ldots + P(X = 12) = 18/36 = 1/2\\).</li> </ul> <p>The expectation or expected value (NL: verwachtingswaarde, verwachte waarde) of a discrete random variable, notated \\(\\mu_X\\) or \\(E(X)\\) is:</p> \\[\\mu_X = \\sum_x x \\cdot P(X = x) = \\sum_x x \\cdot f_X(x)\\] <p>The variance (NL: variantie) of a discrete random variable, notated \\(\\sigma_X^2\\) is:</p> \\[\\sigma_X^2 = \\sum_x (x - \\mu_X)^2 \\cdot P(X = x) = \\sum_x (x - \\mu_X)^2 \\cdot f_X(x)\\] <p>De standard deviation (NL: standaardafwijking) of a discrete random variable, notated \\(\\sigma_X\\) is the square root of the variance:</p> \\[\\sigma_X = \\sqrt{\\sigma_X^2}\\]"},{"location":"en/probability-distribution/#probability-density-function","title":"Probability density function","text":"<p>(NL: kansdichtheidsfunctie)</p> <p>For a continuous random variable that can have any real value as an outcome, it is not possible to enumerate the probability \\(P(X = x)\\) for every possible outcome \\(x\\). Here, for every \\(x\\), the probability is \\(P(X = x) = 0\\). Instead, the probability distribution is described by a function that gives the probability of a given outcome \\(x\\) occurring in a given interval \\([a, b] \\subset \\mathbb{R}\\).</p> <p>Working out the full formal mathematical basis of continuous distributions is beyond the scope of this course. However, the properties of a discrete probability distribution remain valid:</p> <ul> <li> <p>The sum of all probabilities is 1, which corresponds to the total area between the X-axis and the probability density function \\(f\\).</p> \\[\\int_{-\\infty}^{+\\infty} f(x) \\mathrm{d}x = 1\\] </li> <li> <p>The probability that a continuous random variable \\(X\\) falls in a given interval is \\([a, b]\\) \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x) \\, \\mathrm{d}x\\), which always lies between \\(0\\) and \\(1\\).</p> \\[0 \\leq \\int_{a}^{b} f(x) \\mathrm{d}x \\leq 1\\] </li> <li> <p>The complement rule also applies, so \\(P(X \\leq a) = 1 - P(X \\geq a)\\).</p> \\[\\int_{-\\infty}^{a} f(x) \\mathrm{d}x = 1 - \\int_{a}^{+\\infty} f(x) \\mathrm{d}x\\] </li> </ul> <p>We also call a probability \\(P(X \\leq a)\\) a left-tail probability, \\(P(X \\geq a)\\) a right-tail probability.</p>"},{"location":"en/probability-distribution/#well-known-probability-distributions","title":"Well-known probability distributions","text":"<p>Here we list the probability distributions that are discussed in this course. For a more comprehensive list, see e.g. Wikipedia.</p> <ul> <li>The normal distribution</li> <li>The Student's t distribution</li> <li>The uniform distribution</li> <li>The \\(\\chi^2\\) distribution (chi-squared)</li> </ul>"},{"location":"en/probability/","title":"probability","text":"<p>(NL: kans, waarschijnlijkheid)</p> <p>A probability is a number that indicates how likely it is that a certain event will happen during an experiment. In other words, the probability represents the relative frequency of the occurrence of the event at hand when performing a large number of (independent) experiments.</p>"},{"location":"en/probability/#universe-sample-space","title":"universe, sample space","text":"<p>The set of all possible outcomes of an event is called the sample space or universe, noted as \\(\\Omega\\) (Greek capital letter Omega).</p> <p>Events are subsets of $\\Omega $ and are typically noted as a capital letter (e.g. \\(A, B, \\ldots\\)).</p>"},{"location":"en/probability/#axioms-of-probability","title":"axioms of probability","text":"<p>Probabilities must meet the following conditions:</p> <ol> <li>Probabilities are nonnegative: \\(P(A) \\geq 0\\) for each \\(A\\)</li> <li>The universe has probability 1: \\(P(\\Omega) = 1\\)</li> <li> <p>Sum rule: if \\(A\\) and \\(B\\) are disjuoint events (i.e. \\(A \\cap B = \\emptyset\\)), then it holds that:</p> <p>\\(P(A\\cup B) = P(A) + P(B).\\)</p> </li> </ol>"},{"location":"en/probability/#properties","title":"properties","text":"<p>From the three axioms of probability, we can derive \\emph{all}\\/ properties of probabilities.</p> <p>Some important ones are listed below:</p> <ul> <li> <p>Complement rule: For each event \\(A\\), it holds that:</p> <p>\\(P(\\overline{A}) = 1  - P(A)\\)</p> <p>with \\(\\overline{A} = \\Omega \\setminus A\\), the probability that event \\(A\\) does NOT occur.</p> </li> <li> <p>The impossible event has probability zero: \\(P(\\emptyset) = 0\\).</p> </li> <li> <p>The general sum rule: For each event \\(A\\) and \\(B\\), it holds that:</p> <p>\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\)</p> </li> </ul>"},{"location":"en/probability/#independent-events","title":"independent events","text":"<p>Two events are independent if and only if:</p> <p>\\(P(A \\cap B) = P(A)P(B)\\)</p>"},{"location":"en/probability/#contitional-probability","title":"contitional probability","text":"<p>The probability that event \\(A\\) will occur on the condition that event \\(b\\) will occur, is notated with \\(P(A|B)\\)</p>"},{"location":"en/range/","title":"range","text":"<p>(NL: bereik)</p> <p>The range of a sample or population \\(X\\) is calculated as:</p> \\[ \\max(X) - \\min(X) \\] <p>With \\(\\max(X)\\) the largest value and \\(\\min(X)\\) the smallest value in \\(X\\).</p> <p>The range is a measure of dispersion for quantitative variables.</p>"},{"location":"en/region-of-acceptance/","title":"region of acceptance","text":"<p>(NL: aanvaardingsgebied)</p> <p>In the context of hypothesis tests, the region of acceptance is the set of all possible values for the test statistic for which we will accept the null hypothesis.</p> <p>Or, in other words, this is the set of all values for the test statistic for which the p-value \\(p\\) is greater than the significance level \\(\\alpha\\).</p> <p>The values for which we reject the null hypothesis, form the critical region. The border between both areas is called the critical value.</p>"},{"location":"en/residuals-standardized/","title":"residuals, standardized","text":"<p>(NL: residuen, gestandaardiseerde)</p> <p>Standardized residuals are a measure to determine whether a category in a frequency or contingency table is over- or underrepresented in the sample.</p> <p>A residual is the difference between the observed and the expected value. Standardizing means that the resulting value does not depend on the magnitude of the frequencies, the sample size, or the size of the frequency or contingency table.</p> \\[ r_i = \\frac{o_i-e_i}{\\sqrt{e_i (1-\\pi_i)}} \\] <p>Where:</p> <ul> <li>\\(i\\) = index of the category</li> <li>\\(r_i\\) = standardized residual of category \\(i\\)</li> <li>\\(o_i\\) = observed frequency</li> <li>\\(e_i\\) = expected frequency</li> <li>\\(\\pi_i\\) = proportion of the \\(i\\)-th category in the sample (relative frequency)</li> </ul> <p>You can interpret the value \\(r_i\\) as follows:</p> <ul> <li>If \\(r_i &lt; -2\\), then category \\(i\\) is underrepresented in the sample.</li> <li>If \\(-2 \\leq r_i \\leq 2\\), then category \\(i\\) is proportionally represented in the sample.</li> <li>If \\(r_i &gt; 2\\), then category \\(i\\) is overrepresented in the sample.</li> </ul>"},{"location":"en/sample-random/","title":"sample, random","text":"<p>(NL: steekproef, aselecte)</p> <p>A sample is random when every individual in the population has an equal chance of being selected in a sample.</p>"},{"location":"en/sample-representative/","title":"sample, representative","text":"<p>(NL: steekproef, representatieve)</p> <p>A sample is representative if the properties of the population are also reflected within the sample.</p> <p>For example, if in a population 53% identify themselves as female, 46% as male, and 1% as nonbinary, then as a researcher you want these proportions to be reflected in a sample as well.</p> <p>Small deviations are acceptable, though, and a researcher can verify whether this is the case using a chi-squared goodness-of-fit test.</p>"},{"location":"en/sample-size/","title":"sample size","text":"<p>(NL: steekproefgrootte)</p> <p>The sample size is the number of elements or observations \\(n\\) in a sample.</p>"},{"location":"en/sample/","title":"sample","text":"<p>(NL: steekproef)</p> <p>A sample is a subset from a population on which the research is conducted.</p> <p>Under certain circumstances, you may assume that results obtained in the sample also apply to the population as a whole.</p> <p>A \"good\" sample has several properties:</p> <ul> <li>the sample is random</li> <li>the sample is sufficiently large</li> <li>the sample is representative for the population</li> </ul> <p>Ideally, a researcher would do the following to draw a sample from a population:</p> <ul> <li>first and foremost, the population must be well defined</li> <li>then you can compile a sampling frame, i.e. a list of all individuals in a population</li> <li>then the researcher randomly selects a number of individuals</li> </ul> <p>It is often difficult or impossible to set up a sampling frame. In such cases, the researcher chooses a different sampling method and tries to approximate the properties listed above as closely as possible within the available time and budget.</p> <p>Even under the best of circumstances, the result within a sample is likely to deviate from the \"true\" value in the population, although we hope we can approach it sufficiently. So by taking a sample we introduce errors.</p>"},{"location":"en/sampling-errors/","title":"sampling errors","text":"<p>(NL: steekproeffouten)</p> <p>When researchers investigate a population based on a sample, it is inevitable that errors are made, i.e. results of measurements and analyses within the sample will not correspond to the true value over the entire population.</p> <p>The way we take a sample can influence the results.</p>"},{"location":"en/sampling-errors/#sampling-error","title":"sampling error","text":"<p>We discern between random or systematic sampling errors:</p>"},{"location":"en/sampling-errors/#random-sampling-error","title":"random sampling error","text":"<p>Random sampling errors are only due to chance and cannot be avoided. Every time you take a random sample, you will get a different result within that sample.</p>"},{"location":"en/sampling-errors/#systematic-sampling-error","title":"systematic sampling error","text":"<p>A systematic sampling error is worse, because it can cause the results to be biased and therefore no longer be representative for the population. Examples of systematic sampling errors:</p> <ul> <li>In an online survey, only people with internet access are selected. So this sample is no longer random.</li> <li>If you conduct a survey in which people participate voluntarily, you have a greater chance that people who are also interested in the subject participate. This can also have an impact on the results.</li> </ul>"},{"location":"en/sampling-errors/#non-sampling-error","title":"non-sampling error","text":"<p>After taking the sample, errors can also be made in the measurement and analysis. In this case we speak of non-sampling errors and again we distinguish between random and systematic:</p>"},{"location":"en/sampling-errors/#random-non-sampling-error","title":"random non-sampling error","text":"<p>For example, a respondent accidentally selects or fills out a wrong answer in a survey.</p>"},{"location":"en/sampling-errors/#systematic-non-sampling-error","title":"systematic non-sampling error","text":"<p>Examples:</p> <ul> <li>a measuring device is not calibrated correctly and systematically gives a slightly higher value than ther actual one</li> <li>respondents intentionally underestimate or overestimate reality (e.g. when asked about how much you smoke or drink alcohol on a daily basis)</li> </ul>"},{"location":"en/sampling-frame/","title":"sample frame","text":"<p>(NL: steekproefkader)</p> <p>A sampling frame is a list of all individuals who are members of a population.</p>"},{"location":"en/scatter-plot/","title":"scatter plot","text":"<p>(NL: spreidingsdiagram)</p> <p>TODO</p>"},{"location":"en/significance-level/","title":"significance level","text":"<p>(NL: significantieniveau)</p> <p>In the context of statistical hypothesis tests, the significance level (\\(\\alpha\\)) is the probability that the null hypothesis is rejected when it is actually true.</p> <p>The significance level is related to the confidence level (\\(1 - \\alpha\\)) of a confidence interval.</p>"},{"location":"en/standard-error/","title":"standard error","text":"<p>(NL: standaardfout)</p> <p>In the context of the Central Limit Theorem, the standard error is defined as the standard deviation divided by the square root of the sample size:</p> \\[\\text{SE} = \\frac{\\sigma}{\\sqrt{n}}\\] <p>This value is used for calculating confidence intervals.</p>"},{"location":"en/t-distribution/","title":"t-distribution","text":"<p>Also: Student's t-distribution</p> <p>(NL: t-verdeling)</p> <p>The t-distribution (also: Student's t-distribution) is a continuous probability distribution that is used instead of the normal distribution when the standard deviation of a population is not known or when the sample size is not large enough.</p> <p>The probability density function looks like that of the normal distribution, but is \"flatter\" and has wider \"tails\". The t-distribution also takes the sample size \\(n\\) into account, via an extra parameter, the degrees of freedom or \\(n-1\\).</p> <p></p> <p>The cumulative probability density function looks like this:</p> <p></p> <p>The \\(t\\) distribution was developed by the English statistician, chemist and brewer William Sealy Gosset, who published under the pseudonym \"Student\". The distribution was first described in 1908 in an article in the journal Biometrika.</p>"},{"location":"en/t-test/","title":"t-test","text":"<p>(NL: t-toets)</p> <p>The t-test is a statistical hypothesis test that is used as an alternative to the z-test when the population standard deviation \\(\\sigma\\) is unknown or when the sample size is too small (\\(n&lt;30\\)). The test is also used to determine whether the mean of two samples is equal.</p> <p>The conditions for the t-test are:</p> <ul> <li>the sample must be random</li> <li>the investigated stochastic variable must be normally distributed</li> </ul>"},{"location":"en/t-test/#one-sample-t-test","title":"one sample t-test","text":"<p>The procedure of the t-test for one sample is almost identical to that of the z-test, with the only difference that you use the Student-t distribution with \\(n-1\\) degrees of freedom instead of the normal distribution. The standard deviation of the sample is used as an estimator of the population standard deviation \\(\\sigma\\).</p>"},{"location":"en/t-test/#two-sample-t-test","title":"two sample t-test","text":"<p>The t-test can also be used to determine the difference in means of two samples. We distinguish two cases:</p> <ul> <li>Independent samples: the two samples are taken separately and the test assesses whether the means of the two samples are equal or not.</li> <li>Paired samples: for each observation in the first sample, there is a corresponding observation in the second sample (for example, once before and once after a certain intervention). The test assesses whether or not the mean of the differences between the two measurements is equal to zero.</li> </ul>"},{"location":"en/test-statistic/","title":"test statistic","text":"<p>(NL: toetsingsgrootheid)</p> <p>In the context of a statistical hypothesis test, the test statistic is a value that is calculated from the sample to determine whether the null hypothesis can or cannot be rejected.</p>"},{"location":"en/value-expected/","title":"value, expected","text":"<p>(NL: waarde, verwachte)</p> <p>The expected value of a stochastic variable is the average of all values the variable can take, weighted by the probability that value occurs.</p> <p>For a discrete stochastic variable, we denote the expected value as \\(\\mu_X\\) or \\(E(X)\\) and calculate it as follows:</p> \\[\\mu_x = \\sum_{i=1}^{n} x_i \\cdot P(X = x_i)\\] <p>with \\(\\Omega = {x_1, \\ldots, x_n}\\) the sample space of \\(X\\).</p> <p>For a continuous stochastic variable, you get:</p> \\[\\mu_x = \\int_{-\\infty}^{+\\infty} x \\cdot f(x) \\, \\mathrm{d}x\\] <p>where \\(f(x)\\) is the probability density function.</p> <p>You can also calculate the variance and standard deviation of a stochastic variable.</p>"},{"location":"en/variable-random/","title":"random variable","text":"<p>(NL: stochastische variabele)</p> <p>Also: stochastic variable</p> <p>Informally, a random variable is a quantity whose value is a real number that depends in some way on chance. Examples:</p> <ul> <li>The number of eyes thrown with a die</li> <li>Taking a sample from a population</li> <li>The height of a person</li> <li>...</li> </ul> <p>Formally, a random variable is defined as a function that assigns a real number to each possible outcome of an experiment. The set of all possible outcomes of an experiment is called the universe or outcome space, denoted as \\(\\Omega\\) (Greek capital letter Omega).</p> \\[X: \\Omega \\to \\mathbb{R}: \\omega \\mapsto X(\\omega)\\] <p>Example: the total number of eyes thrown with two dice can be formalized as follows:</p> \\[X: \\Omega \\to \\mathbb{R}: (a,b) \\mapsto a+b\\] <p>With \\((a, b) \\in \\Omega = \\{ (1,1), (1,2), \\ldots, (6,6) \\}\\) (= all possible combinations of throwing 2 dice). The value range of \\(X\\) is then \\(\\{2, 3, \\ldots, 12\\}\\).</p> <p>If the value range of a random variable \\(X\\) is finite (as in this example) or countably infinite (e.g. \\(\\mathbb{N}, \\mathbb {Z}, \\mathbb{Q}\\)), we speak of a discrete random variable. If the range of values is uncountably infinite (e.g. \\(\\mathbb{R}, \\mathbb{R^+}\\)), we speak of a continuous random variable.</p> <p>For a random variable \\(X\\), we are particularly interested in the probability distribution of \\(X\\).</p>"},{"location":"en/variance/","title":"variance","text":"<p>(NL: variantie)</p> <p>The variance is a measure of dispersion that is ideally suited for quantitative variables that are normally distributed.</p> <p>The standard deviation (NL: standaardafwijking) is also calculated from the variance, which is used even more often.</p> <p>The variance and standard deviation are sensitive to outliers. For data that is not normally distributed, mean and standard deviation are not a good summary of the data. In that case, the median and interquartile range can serve as alternatives.</p>"},{"location":"en/variance/#variance-of-a-sample","title":"variance of a sample","text":"<p>The variance \\(s^2\\) of a sample \\(X = \\{x_1, \\ldots, x_n\\}\\) of size \\(n\\) with mean \\(\\overline{x}\\) is calculated as follows:</p> \\[s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2\\]"},{"location":"en/variance/#standard-deviation-of-a-sample","title":"standard deviation of a sample","text":"<p>The standard deviation is the square root of the variance:</p> \\[s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2}\\]"},{"location":"en/variance/#variance-of-a-population","title":"variance of a population","text":"<p>The variance \\(\\sigma\\) of a population of size \\(N\\) with mean \\(\\mu\\) is calculated as follows:</p> \\[\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]"},{"location":"en/variance/#standard-deviation-of-a-population","title":"standard deviation of a population","text":"<p>The standard deviation is the square root of the variance:</p> \\[\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2}\\]"},{"location":"en/variance/#variance-and-standard-deviation-of-a-discrete-stochastic-variable","title":"variance and standard deviation of a discrete stochastic variable","text":"<p>The variance \\(\\sigma_X^2\\) of a discrete stochastic variable \\(X\\) with expected value \\(\\mu_X\\) is calculated as follows:</p> \\[\\sigma_X^2 = \\sum_x (x - \\mu_X)^2 \\cdot P(X = x)\\] <p>The standard deviation is then \\(\\sigma_X = \\sqrt{\\sigma_X^2}\\).</p>"},{"location":"en/variance/#variance-and-standard-deviation-of-a-continuous-stochastic-variable","title":"variance and standard deviation of a continuous stochastic variable","text":"<p>The variance \\(\\sigma_X^2\\) of a continuous stochastic variable \\(X\\) with expected value \\(\\mu_X\\) is calculated as follows:</p> \\[\\sigma_X^2 = \\int_{-\\infty}^{+\\infty} (x - \\mu_X)^2 \\cdot f_X(x) \\, \\mathrm{d}x\\] <p>Again, the standard deviation is \\(\\sigma_X = \\sqrt{\\sigma_X^2}\\).</p>"},{"location":"en/z-score/","title":"z-score","text":"<p>Also: standard score</p> <p>(NL: z-score)</p> <p>The z-score is a number that indicates how many standard deviations a certain value deviates from the mean.</p> <p>The z-score of an observation \\(x\\) from a stochastic variable \\(X\\) with expectation \\(\\mu\\) and standard deviation \\(\\sigma\\) is given by:</p> \\[z = \\frac{x - \\mu}{\\sigma}\\]"},{"location":"en/z-test/","title":"z-test","text":"<p>(NL: z-toets)</p> <p>The z-test is a statistical hypothesis test to verify a statement about the population mean, more specifically whether the population mean \\(\\mu\\) is equal to a certain value, denoted as \\(\\mu_0\\).</p> <p>The z-test can be used under the condition that:</p> <ul> <li>the sample is random</li> <li>the sample is large enough (\\(n \\geq 30\\))</li> <li>the test statistic is normally distributed</li> <li>the standard deviation of the population is known</li> </ul> <p>Initially, we assume that this statement is true, i.e. that \\(\\mu = \\mu_0\\). This is the null hypothesis. Then the central limit theorem applies and the sample mean follows a normal distribution with expectation \\(\\mu_0\\) and standard deviation \\(\\sigma/\\sqrt{n}\\).</p> <p>The test statistic is then the sample mean. This will deviate from the expectation \\(\\mu_0\\), but the question is whether this difference is significant.</p> <p>There are three variants of this test:</p> <ul> <li>Right-tailed:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu &gt; \\mu_0\\)</li> <li>P-value: \\(p = P(Z &gt; z)\\) with \\(z\\) the z-score \\(z = \\frac{\\overline{x} - \\mu_0}{\\sigma/\\sqrt{n}}\\)</li> <li>Critical value: \\(g = \\overline{x} + z_{\\alpha} \\frac{\\sigma}{\\sqrt{n}}\\) with \\(z_{\\alpha}\\) such that \\(P(Z &gt; z_{\\alpha}) = \\alpha\\)</li> <li>reject the null hypothesis if \\(\\overline{x} &gt; g\\)</li> </ul> </li> <li>Left-tailed:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu &lt; \\mu_0\\)</li> <li>p-value: \\(p = P(Z &lt; z)\\)</li> <li>critical value: \\(g = \\overline{x} - z_{\\alpha} \\frac{\\sigma}{\\sqrt{n}}\\)</li> <li>reject the null hypothesis if \\(\\overline{x} &lt; g\\)</li> </ul> </li> <li>Two-tailed:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu \\neq \\mu_0\\)</li> <li>p-value: \\(p = 2P(Z &gt; z)\\)</li> <li>critical values:<ul> <li>\\(g_1 = \\overline{x} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)</li> <li>\\(g_2 = \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)</li> </ul> </li> <li>reject the null hypothesis if \\(\\overline{x} &lt; g_1\\) or \\(\\overline{x} &gt; g_2\\)</li> </ul> </li> </ul> <p>In practice, the \\(z\\)-test is only seldom used because the population standard deviation is often unknown. In that case, the t-test is used.</p>"},{"location":"nl/aanvaardingsgebied/","title":"aanvaardingsgebied","text":"<p>(EN: region of acceptance)</p> <p>In de context van hypothesetoetsen is het aanvaardingsgebied de verzameling van alle mogelijke waarden voor de toetsingsgrootheid waarvoor we de nulhypothese zullen aanvaarden.</p> <p>Of, met andere woorden, dit is de verzameling van alle waarden voor de toetsingsgrootheid waarvoor de overschrijdingskans groter is dan het significantieniveau.</p> <p>De waarden waarvoor we de nulhypothese verwerpen, vormen het kritieke gebied. De grens tussen beide gebieden noemen we de kritieke grenswaarde.</p>"},{"location":"nl/alternatieve-hypothese/","title":"alternatieve hypothese","text":"<p>(EN: alternative hypothesis)</p> <p>In de context van hypothesetoetsen is alternatieve hypothese (vaak genoteerd als \\(H_1\\)) een veronderstelling over een populatieparameter die we willen testen.</p> <p>De alternatieve hypothese stelt typisch de veronderstelling voor dat er een significant verschil is tussen de populatieparameter en een bepaalde waarde, of dat er wel een verband bestaat tussen twee variabelen.</p> <p>De procedure van de toets is gebaseerd op de veronderstelling dat de nulhypothese waar is. Als we dan op een tegenspraak stuiten, wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard.</p>"},{"location":"nl/analyse-van-twee-variabelen/","title":"analyse van twee variabelen","text":"<p>(EN: analysis, bivariate)</p> <p>Analyse van twee variabelen is een verzamelnaam voor een aantal technieken die gebruikt worden om het verband tussen twee variabelen te onderzoeken. Afhankelijk van de onderzoeksvraag wordt \u00e9\u00e9n van de variabelen als onafhankelijke variabele beschouwd, en de andere als afhankelijke variabele.</p> <p>Geschikte technieken voor de visualisatie of analyse van twee variabelen hangen af van het meetniveau van de variabelen. In deze cursus beperken we ons tot de technieken die samengevat zijn in de tabellen hieronder.</p>"},{"location":"nl/analyse-van-twee-variabelen/#visualisatietechnieken","title":"Visualisatietechnieken","text":"Onafhankelijke variabele Afhankelijke variabele Techniek Kwalitatief Kwalitatief Geclusterd staafdiagram \" \" Rependiagram \" \" Moza\u00efekdiagram Kwalitatief Kwantitatief Boxplot \" \" Dichtheidsdiagram Kwantitatief Kwantitatief Spreidingsdiagram"},{"location":"nl/analyse-van-twee-variabelen/#analysetechnieken","title":"Analysetechnieken","text":"Onafhankelijke variabele Afhankelijke variabele Toets Maat Kwalitatief Kwalitatief \\(\\chi^ 2\\)-onafhankelijkheidstoets Cram\u00e9r's V Kwalitatief Kwantitatief t-toets Cohen's d Kwantitatief Kwantitatief Correlatieco\u00ebffici\u00ebnt <ul> <li>In het geval van twee kwantitatieve variabelen onderzoeken we in deze cursus enkel of er een lineair verband bestaat tussen de twee variabelen.</li> <li>Merk op dat er wel degelijk een statistische toetsingsprocedure bestaat om lineaire correlatie te onderzoeken, maar dat deze niet in deze cursus behandeld wordt.</li> </ul>"},{"location":"nl/bereik/","title":"bereik","text":"<p>(EN: range)</p> <p>Het bereik van een steekproef of populatie \\(X\\) wordt berekend als:</p> \\[ \\max(X) - \\min(X) \\] <p>Met \\(\\max(X)\\) de grootste waarde en \\(\\min(X)\\) de kleinste waarde in \\(X\\).</p> <p>Het bereik is een spreidingsmaat voor kwantitatieve variabelen.</p>"},{"location":"nl/betrouwbaarheidsinterval/","title":"betrouwbaarheidsinterval","text":"<p>(EN: confidence interval)</p> <p>Een betrouwbaarheidsinterval is een interval dat berekend wordt op basis van een steekproef als een schatting voor een onbekende populatieparameter. Het interval geeft met een bepaalde (gekozen) zekerheid aan binnen welke grenzen de populatieparameter ligt.</p>"},{"location":"nl/betrouwbaarheidsniveau/","title":"betrouwbaarheidsniveau","text":"<p>(EN: confidence level)</p> <p>Het betrouwbaarheidsniveau \\(1-\\alpha\\) stelt de theoretische kans voor dat een betrouwbaarheidsinterval de onbekende populatieparameter bevat.</p> <p>Het betrouwbaarheidsniveau is gerelateerd aan het significantieniveau \\(\\alpha\\) van een hypothesetoets.</p>"},{"location":"nl/boxplot/","title":"boxplot","text":"<p>(EN: boxplot)</p>"},{"location":"nl/centrale-limietstelling/","title":"centrale limietstelling","text":"<p>(EN: central limit theorem)</p> <p>De centrale limietstelling zegt dat de verdeling van de gemiddelden van steekproeven steeds meer op de normale verdeling lijkt te gaan lijken naarmate de steekproefgrootte groter wordt.</p> <p>Of, specifieker, als je een voldoende grote (\\(n &gt;30\\)) aselecte steekproef neemt uit een populatie met verwachte waarde \\(\\mu\\) en standaardafwijking \\(\\sigma\\), dan zal het steekproefgemiddelde \\(\\bar{x}\\) een normaalverdeling hebben met verwachte waarde \\(\\mu\\) en standaardafwijking \\(\\frac{\\sigma}{\\sqrt{n}}\\). Dit geldt ongeacht de kansverdeling van de populatie!</p> <p>De centrale limietstelling is een belangrijke basis voor veel statistische methoden, zoals betrouwbaarheidsintervallen en hypothesetoetsen. Ze dicteert de voorwaarden waaronder we een resultaat uit een steekproef (tot op zekere hoogte) kunnen veralgemenen naar de populatie.</p>"},{"location":"nl/centrummaat/","title":"centrummaat","text":"<p>(EN: measure of central tendency, mean)</p> <p>Een centrummaat voor een variabele is een waarde die als \"typisch\" geldt voor die groep. Er bestaan verschillende manieren om een centrummaat te berekenen. Hieronder zijn slechts enkele opgesomd.</p> <p>Afhankelijk van het meetniveau zijn er specifieke centrummaten bij uitstek geschikt:</p> <ul> <li>Kwalitatieve variabelen: modus</li> <li>Kwantitatieve variabelen: rekenkundig gemiddelde, mediaan</li> </ul> <p>Naast een centrummaat gebruikt men typisch ook een spreidingsmaat om de variabiliteit van waarnemingen voor die variabele uit te drukken.</p>"},{"location":"nl/chi-kwadraat/","title":"chi-kwadraat","text":"<p>(EN: chi squared)</p> <p>Chi-kwadraat (Genoteerd \\(\\chi^2\\), met de Griekse letter \"chi\") is een statistische grootheid die gebruikt wordt om te bepalen of er een verband bestaat tussen twee kwalitatieve variabelen.</p> <p>De waarde wordt berekend op een kruistabel, waarin de frequenties van de combinaties van de twee variabelen worden weergegeven. De waarde geeft aan hoe ver waargenomen frequenties afwijken van de verwachte frequenties als de twee variabelen onafhankelijk van elkaar zouden zijn.</p> \\[\\chi^2 = \\sum \\frac{(o_i - e_i)^2}{e_i}\\] <p>waarbij:</p> <ul> <li>\\(\\chi^2\\) = chi-kwadraatwaarde</li> <li>\\(o_i\\) = waargenomen frequentie van combinatie \\(i\\)</li> <li>\\(e_i\\) = verwachte frequentie van combinatie \\(i\\)</li> </ul> <p>Als de geobserveerde waarden volledig overeenkomen met de verwachte waarden, is \\(\\chi^2 = 0\\). Hoe groter de waarde, hoe groter de afwijking tussen de geobserveerde en verwachte waarden. De \\(\\chi^2\\)-verdeling wordt gebruikt om de significantie van de afwijking te bepalen.</p> <p>Chi-kwadraat wordt gebruikt in \\(\\chi^2\\)-kwadraattoetsen om te bepalen of er een verband bestaat tussen twee kwalitatieve variabelen (onafhankelijkheidstoets), of om te bepalen of de verdeling van een kwalitatieve variabele overeenkomt met een bepaalde verdeling (aanpassingstoets).</p>"},{"location":"nl/chi-kwadraattoets/","title":"chi-kwadraattoets","text":"<p>(EN: chi-squared test)</p>"},{"location":"nl/chi-kwadraattoets/#onafhankelijkheidstoets","title":"Onafhankelijkheidstoets","text":"<p>De \\(\\chi^2\\)-onafhankelijkheidstoets wordt gebruikt om te bepalen of er een associatie is tussen twee kwalitatieve variabelen. De nulhypothese is dat er geen verband is tussen de variabelen (ze zijn m.a.w. onafhankelijk). De alternatieve hypothese is dat er wel een verband is.</p> <p>De toets wordt uitgevoerd op een kruistabel, waarin de frequenties van de combinaties van de twee variabelen worden weergegeven. De waarde geeft aan hoe ver de waargenomen frequenties afwijken van de verwachte frequenties als de twee variabelen onafhankelijk van elkaar zouden zijn.</p> <p>In een kruistabel met onafhankelijke variabelen is de kansverdeling van de \\(\\chi^2\\)-waarde bekend en gegeven door de zgn. \\(\\chi^2\\)-verdeling met \\((r-1)(c-1)\\) vrijheidsgraden, waarbij \\(r\\) het aantal rijen en \\(c\\) het aantal kolommen in de kruistabel is. Hierdoor kunnen we de significantie van de afwijking bepalen.</p> <p>De toetsingsprocedure verloop als volgt:</p> <ul> <li>Stap 1: Formuleer de nulhypothese \\(H_0\\) en de alternatieve hypothese \\(H_1\\).<ul> <li>\\(H_0\\): er is geen verband tussen de variabelen</li> <li>\\(H_1\\): er is wel een verband tussen de variabelen</li> </ul> </li> <li>Stap 2: Kies het significantieniveau \\(\\alpha\\).</li> <li>Stap 3: Bereken de toetsingsgrootheid, in dit geval de \\(\\chi^2\\)-waarde op basis van de observaties in de kruistabel (\\(\\chi^2_{\\text{obs}}\\)).</li> <li>Stap 4: Ofwel:<ul> <li>Bepaal de kritieke grenswaarde \\(g\\) zodat \\(P(\\chi^2 &gt; g) = \\alpha\\).</li> <li>Bepaal de overschrijdingskans \\(p = P(\\chi^2 &gt; \\chi^2_{\\text{obs}})\\).</li> </ul> </li> <li>Stap 5: Trek een besluit:<ul> <li>Aanvaard \\(H_0\\) als \\(p &gt; \\alpha\\) of \\(\\chi^2_{\\text{obs}} &lt; g\\).</li> <li>Verwerp \\(H_0\\) als \\(p \\leq \\alpha\\) of \\(\\chi^2_{\\text{obs}} \\geq g\\).</li> </ul> </li> </ul> <p>Merk op dat de \\(\\chi^2\\)-toets altijd rechtszijdig is.</p>"},{"location":"nl/chi-kwadraattoets/#aanpassingstoets","title":"Aanpassingstoets","text":"<p>De \\(\\chi^2\\)-aanpassingstoets wordt gebruikt om te bepalen of de verdeling van een steekproef overeenkomt met een bepaalde verdeling. Een situatie waar dit van toepassing is, is bijvoorbeeld wanneer je een steekproef genomen hebt uit een populatie waarvan je de verdeling kent, en je wil nagaan of de steekproef representatief is voor de populatie (d.w.z. of de steekproefverdeling overeenkomt met de populatieverdeling).</p> <p>De nulhypothese is dat de steekproefverdeling overeenkomt met de gegeven verdeling. De alternatieve hypothese is dat de steekproefverdeling niet overeenkomt met de gegeven verdeling.</p> <p>Om de toets uit te kunnen voeren heb je de frequentietabel nodig van de steekproef (genoteerd \\(o_i\\)), en de verwachte frequenties (genoteerd \\(\\pi_i\\)) in de populatie. De verwachte waarden \\(e_i\\) kunnen dan berekend worden met \\(e_i = n \\cdot \\pi_i\\), waarbij \\(n = \\sum_{i=1}^k o_i\\) het totaal aantal waarnemingen in de steekproef is en \\(k\\) het aantal categorie\u00ebn in de verdeling. De kansverdeling van \\(\\chi^2\\) is in dit geval gegeven door de \\(\\chi^2\\)-verdeling met \\(k-1\\) vrijheidsgraden.</p> <p>De berekening van \\(\\chi^2\\) en de toetsingsprocedure verlopen verder analoog aan de onafhankelijkheidstoets.</p>"},{"location":"nl/chi-kwadraatverdeling/","title":"chi-kwadraatverdeling","text":"<p>(EN: chi-squared distribution)</p> <p>De \\(\\chi^2\\)-verdeling is een kansverdeling die gebruikt wordt in de statistiek. De verdeling is afhankelijk van een parameter, namelijk het aantal vrijheidsgraden. De \\(\\chi^2\\)-verdeling wordt vaak gebruikt in de context van de \\(\\chi^2\\)-toets.</p> <p></p>"},{"location":"nl/cochrans-regels/","title":"Cochran's regels","text":"<p>(EN: Cochran's rules)</p> <p>De regels van Cochrane zijn een reeks vuistregels om te bepalen of de resultaten van een chi-kwadraattoets betrouwbaar zijn. Meer bepaald zouden er in elke categorie van een kruistabel of frequentietabel \"voldoende\" waarnemingen moten zijn om de chi-kwadraattoets te kunnen toepassen. De regels van Cochrane bepalen hoeveel \"voldoende\" precies is.</p> <p>De regels worden doorgaans als volgt geformuleerd:</p> <ol> <li>Elke cel in de tabel moet een verwachte frequentie hebben van minstens 1.</li> <li>In minstens 80% van de cellen moet de verwachte frequentie minstens 5 zijn (of ten hoogste 20% van de cellen mag een verwachte frequentie van minder dan 5 hebben).</li> </ol> <p>De regels zijn genoemd naar de Amerikaanse statisticus William G. Cochran aan wie ze zijn toegeschreven, gebaseerd op zijn werk in de jaren 1950 (Cochran, 1952; 1954, p.420). Voor een uitgebreide bespreking van de regels van Cochrane, zie Kroonenberg &amp; Verbeek (2018).</p>"},{"location":"nl/cochrans-regels/#referenties","title":"Referenties","text":"<p>Cochran, W. G. (1952). The \u03c72 test of goodness of fit. The Annals of Mathematical Statistics, 23(3), 315-345. https://doi.org/10.1214/aoms/1177729380</p> <p>Cochran, W. G. (1954). Some Methods for Strengthening the Common \u03c7 2 Tests. Biometrics, 10(4), 417-451. https://doi.org/10.2307/3001616</p> <p>Kroonenberg, P. M., &amp; Verbeek, A. (2018). The Tale of Cochran\u2019s Rule: My Contingency Table has so Many Expected Values Smaller than 5, What Am I to Do? The American Statistician, 72(2), 175\u2013183. https://doi.org/10.1080/00031305.2017.1286260</p>"},{"location":"nl/cohens-d/","title":"Cohen's d","text":"<p>(EN: Cohen's d)</p> <p>Cohen's \\(d\\) is een maat voor de sterkte van het verschil tussen twee groepen. Het wordt berekend als het verschil tussen de gemiddelden van de twee groepen, gedeeld door de standaardafwijking van de steekproef.</p> \\[d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s}\\] <p>met \\(s\\) een puntschatter voor de standaardafwijking van de populatie, gebaseerd op de observaties in beide groepen:</p> \\[s = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\\] <p>Hierbij zijn \\(\\bar{x}_1\\) en \\(\\bar{x}_2\\) de gemiddelden van de twee groepen,n \\(s_1\\) en \\(s_2\\) de standaardafwijkingen van de twee groepen, \\(n_1\\) en \\(n_2\\) zijn de steekproefgroottes van de twee groepen.</p> <p>De interpretatie van (de absolute waarde van) Cohen's \\(d\\) is als volgt:</p> \\(d\\) Interpretatie 0.01 Zeer klein verschil 0.20 Klein verschil 0.50 Gemiddeld verschil 0.80 Groot verschil 1.20 Zeer groot verschil 2.00 Enorm verschil <p>Deze interpretatie is echter niet absoluut. De interpretatie van een bepaalde waarde van \\(d\\) hangt af van de context en de onderzoeksvraag.</p> <p>In onderwijswetenschappen wordt Cohen's \\(d\\) vaak gebruikt om te beoordelen of een bepaalde interventie in het onderwijs een voldoende groot effect heeft op leerprestaties van studenten. John Hattie heeft een lijst van effectgroottes opgesteld voor verschillende onderwijsinterventies, die hij regelmatig bijwerkt (Waack, 2018). E\u00e9n van zijn bijdragen aan de onderwijswetenschappen is het bewust worden van het feit dat sommige interventies enorm duur en/of tijdrovend zijn, maar slechts een zeer klein effect hebben op de leerprestaties van studenten. Uit het overzicht blijkt ook dat sommige \"hippe\" onderwijsmethoden zoals zelfontdekkend leren, eigenlijk weinig effect hebben op leerprestaties. Om zinvol te zijn, zou een effectgrootte van een interventie minstens 0.40 moeten zijn. Een effectgrootte van 1 zou een zeer groot effect zijn en zou betekenen dat dezelfde leerstof op de helft van de tijd kan verwerkt worden.</p>"},{"location":"nl/cohens-d/#referenties","title":"Referenties","text":"<p>Waack, S. (2018) Hattie Ranking: 252 Influences And Effect Sizes Related To Student Achievement. Opgehaald 2025-03-19 van https://visible-learning.org/hattie-ranking-influences-effect-sizes-learning-achievement/</p>"},{"location":"nl/correlatie/","title":"correlatie","text":"<p>(EN: correlation)</p> <p>In de breedste betekenis is correlatie elk verband tussen twee stochastische variabelen. Meestal bedoelt men echter de mate waarin twee variabelen een lineair verband tonen.</p> <p>Er bestaan verschillende manieren om de correlatie tussen twee variabelen te meten. De meest bekende is de Pearson-correlatieco\u00ebffici\u00ebnt.</p>"},{"location":"nl/correlatie/#covariantie","title":"covariantie","text":"<p>Covariantie is een maat die aangeeft of een verband tussen twee variabelen positief (stijgend) of negatief (dalend) is. De steekproefcovariantie tussen twee variabelen \\(X\\) en \\(Y\\) wordt gedefinieerd als:</p> \\[\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\\] <p>Als de covariantie positief is, betekent dit dat de variabelen samen toenemen. Als de covariantie negatief is, betekent dit dat de variabelen tegengesteld evolueren. Als de covariantie nul is, of dicht bij 0 ligt, betekent dit dat er geen duidelijk stijgend of dalend verband is tussen de variabelen.</p> <p>Merk op dat:</p> <ul> <li> <p>er ook een populatiecovariantie bestaat, met \\(n\\) in de noemer in plaats van \\(n-1\\).</p> </li> <li> <p>de covariantie gevoelig is voor de meeteenheid van de variabelen. Als je observaties omrekent naar een andere meeteenheid, zal de covariantie veranderen!</p> </li> <li> <p>de covariantie is een veralgemening van het begrip variantie. De variantie van een variabele is de covariantie van die variabele met zichzelf.</p> </li> </ul>"},{"location":"nl/correlatie/#correlatiecoefficient","title":"correlatieco\u00ebffici\u00ebnt","text":"<p>Pearson's product-moment correlatieco\u00ebffici\u00ebnt is een maat voor de sterkte en de richting van een lineair verband tussen twee kwantitatieve variabelen.</p> <p>De correlatieco\u00ebffici\u00ebnt van een steekproef is gedefinieerd als:</p> \\[R = \\frac{\\text{Cov(X,Y)}}{s_Xs_Y} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\\] <p>De waarde van \\(R\\) ligt tussen -1 en 1. Een waarde van 1 betekent een perfect positief lineair verband, d.w.z. alle observaties liggen op \u00e9\u00e9n stijgende rechte. Een waarde van -1 betekent een perfect negatief lineair verband, dus dat de observaties op een dalende rechte liggen. Een waarde van 0 betekent dat er geen lineair verband is.</p> <p>Merk op dat:</p> <ul> <li> <p>De correlatieco\u00ebffici\u00ebnt niet gevoelig is voor de meeteenheid van de variabelen. Als je observaties omrekent naar een andere meeteenheid, zal de correlatieco\u00ebffici\u00ebnt niet veranderen.</p> </li> <li> <p>De correlatieco\u00ebffici\u00ebnt niets zegt over de mate van stijging, enkel over de richting. De richtingsco\u00ebffici\u00ebnt van een regressierechte die het best past bij de data, zal daar meer over zeggen.</p> </li> <li> <p>De correlatieco\u00ebffici\u00ebnt op zich niet altijd veel zegt. Een correlatieco\u00ebffici\u00ebnt van 0.8 lijkt te wijzen op een sterk lineair verband, maar dat is niet altijd zo! Het blijft belangrijk om de data te visualiseren en te interpreteren. Kijk bv. naar Kwartet van Anscombe voor een illustratie hiervan.</p> </li> <li> <p>Correlation is not causation! Een hoge correlatieco\u00ebffici\u00ebnt betekent niet noodzakelijk dat er een oorzakelijk verband is tussen de variabelen. Het kan ook zijn dat beide variabelen be\u00efnvloed worden door een derde variabele.</p> </li> </ul>"},{"location":"nl/correlatie/#determinatiecoefficient","title":"determinatieco\u00ebffici\u00ebnt","text":"<p>De determinatieco\u00ebffici\u00ebnt drukt uit welk deel van de variantie van de afhankelijke variabele verklaard wordt door de onafhankelijke variabele.</p> <p>De determinatieco\u00ebffici\u00ebnt gelijk aan het kwadraat van de correlatieco\u00ebffici\u00ebnt \\(R^2\\) en is dus een waarde tussen 0 en 1. Als bijvoorbeeld \\(R^2 = 0.35\\), dan zeggen we dat 35% van de variantie ind de afhankelijke variabele verklaard wordt door de onafhankelijke variabele.</p>"},{"location":"nl/correlatie/#interpretatie-van-r-en-r2","title":"interpretatie van \\(R\\) en \\(R^2\\)","text":"\\(R\\) \\(R^2\\) Interpretatie 0.00 0.00 Geen verband 0.10 0.01 Zeer zwak verband 0.30 0.09 Zwak verband 0.50 0.25 Gemiddeld verband 0.70 0.49 Sterk verband 0.90 0.81 Zeer sterk verband 1.00 1.00 Perfect verband"},{"location":"nl/cramers-v/","title":"Cramer's V","text":"<p>(EN: Cramer's V)</p> <p>Cram\u00e9r's V is een maat voor de associatie tussen twee kwalitatieve variabelen. Het varieert van 0 tot 1, waarbij 0 geen associatie betekent en 1 perfecte associatie. Het is gebaseerd op de chi-kwadraatstatistiek en wordt gedefinieerd als:</p> \\[V = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\\] <p>waarbij \\(\\chi^2\\) de chi-kwadraatstatistiek is, \\(n\\) het aantal observaties en \\(k\\) het aantal categorie\u00ebn in de frequentie- of kruistabel.</p>"},{"location":"nl/effectgrootte/","title":"effectgrootte","text":"<p>(EN: effect size)</p> <p>De effectgrootte is een maat die uitdrukt hoe sterk een verband tussen twee variabelen is.</p> <p>Afhankelijk van de context, en meer bepaald van de meetniveaus van de variabelen, zijn er verschillende methoden om een effectgrootte te defini\u00ebren.</p> <ul> <li> <p>Cramer's V is een maat voor de sterkte van het verband tussen twee kwalitatieve variabelen.</p> </li> <li> <p>Cohen's d is een maat voor het verschil tussen (de gemiddelden van) twee groepen.</p> </li> <li> <p>Pearson's correlatieco\u00ebffici\u00ebnt is een maat voor de sterkte van een lineair verband tussen twee kwantitatieve variabelen.</p> </li> </ul> <p>Naast deze bestaan er nog tientallen definities van effectgroottes, elk met hun eigen toepassingsgebied en interpretatie.</p> <p>Effectgroottes zijn complementair aan hypothesetoetsen. Een hypothesetoets bepaalt of een verband statistisch significant is, terwijl een effectgrootte aangeeft hoe sterk dat verband is.</p>"},{"location":"nl/frequentie/","title":"frequentie","text":"<p>(EN: frequency)</p> <p>De frequentie van een waarde van een variabele in een dataset of steekproef is het aantal keer dat die waarde voorkomt.</p> <p>We onderscheiden enerzijds de absolute frequentie (= het aantal) en anderzijds de relatieve frequentie (= hoeveel percent van het totaal aantal waarnemingen deze waarde aanneemt, als een fractie tussen 0 en 1).</p> <p>De frequenties van elke unieke waarde die voorkomt in de steekproef worden samengevat in een frequentietabel. Een frequentietabel die de frequenties van de combinatie van de waarden van twee variabelen samenvat, noemen we ook een kruistabel.</p>"},{"location":"nl/gemiddelde/","title":"gemiddelde","text":"<p>(EN: arithmetic mean, average)</p> <p>Het gemiddelde is een centrummaat die bij uitstek geschikt is voor kwantitatieve variabelen.</p> <p>Vaak wordt het gemiddelde samen met de standaardafwijking gebruikt om een steekproef te beschrijven. Dit is vooral nuttig voor variabelen die normaal verdeeld zijn.</p>"},{"location":"nl/gemiddelde/#gemiddelde-van-een-steekproef","title":"gemiddelde van een steekproef","text":"<p>Het (rekenkundig) gemiddelde \\(\\overline{x}\\) van een steekproef \\(X = \\{x_1, \\ldots, x_n\\}\\) van grootte \\(n\\) is</p> \\[\\overline{x} = \\frac{1}{n} \\sum_{x=1}^{n} x_i\\]"},{"location":"nl/gemiddelde/#gemiddelde-van-een-populatie","title":"gemiddelde van een populatie","text":"<p>Het (rekenkundig) gemiddelde van een populatie wordt aangeduid met de Griekse letter mu: \\(\\mu\\). De formule is dezelfde als voor het gemiddelde.</p>"},{"location":"nl/grieks-alfabet/","title":"Het Griekse alfabet","text":"<p>(EN: Greek alphabet)</p> <p>In de statistiek (en de wiskunde in het algemeen) worden regelmatig Griekse letters gebruikt. Omdat de meeste studenten wellicht geen Grieks geleerd hebben, geven we hier de letters van het Griekse alfabet.</p> <p>In de linkerkolom geven we telkens de hoofd- en kleine letter (en voor sommige letters een alternatieve schrijfwijze). De middelste kolom is de naam van de Griekse letter en de rechter het equivalent in het Latijnse alfabet.</p> Grieks Naam Equivalent \u0391, \u03b1 alfa a \u0392, \u03b2 beta b \u0393, \u03b3 gamma g \u0394, \u03b4 delta d \u0395, \u03b5 epsilon e \u0396, \u03b6 dzeta dz \u0397, \u03b7 eta ei \u0398, \u03b8 theta th \u0399, \u03b9 iota i \u039a, \u03ba kappa k \u039b, \u03bb lambda l \u039c, \u03bc mu m \u039d, \u03bd nu n \u039e, \u03be xi x, ks \u039f, \u03bf omikron o (\"kleine o\") \u03a0, \u03c0 pi p \u03a1, \u03c1 rho r \u03a3, \u03c3/\u03c2 sigma s \u03a4, \u03c4 tau t \u03a5, \u03c5 upsilin u \u03a6, \u03c6 phi f \u03a7, \u03c7 chi ch \u03a8, \u03c8 psi ps \u03a9, \u03c9 omega oo (\"grote o\")"},{"location":"nl/histogram/","title":"histogram","text":"<p>(EN: histogram)</p> <p>TODO</p>"},{"location":"nl/hypothesetoets/","title":"hypothesetoets","text":"<p>(EN: hypothesis test)</p> <p>Een statistische hypothesetoets is een procedure om te bepalen of een uitspraak of vermoeden over een populatie waaruit een steekproef genomen is klopt.</p> <p>De procedure bestaat uit volgende stappen:</p> <ol> <li>Formuleren van de nulhypothese \\(H_0\\) en de alternatieve hypothese \\(H_1\\).</li> <li>Kiezen van een significantieniveau \\(\\alpha\\).</li> <li>Berekenen van de toetsingsgrootheid op basis van de steekproef</li> <li>Berekenen van:<ul> <li>ofwel de overschrijdingskans \\(p\\)</li> <li>ofwel het kritieke gebied</li> </ul> </li> <li>Conclusie trekken op basis van de overschrijdingskans of het kritieke gebied.</li> </ol> <p>Een statistische toets vertrekt vanuit de veronderstelling dat de nulhypothese waar is en bouwt op basis daarvan een redenering op. Zoals bij een bewijs uit het ongerijmde, is het mogelijk dat we dan op een tegenspraak stuiten. In dat geval wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard.</p> <p>Het trekken van een conclusie op basis van de overschrijdingskans gebeurt als volgt:</p> <ul> <li>Als \\(p \\leq \\alpha\\) dan wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard.</li> <li>Als \\(p &gt; \\alpha\\) dan wordt de nulhypothese niet verworpen.</li> </ul> <p>Of, op basis van het kritieke gebied:</p> <ul> <li>Als de toetsingsgrootheid zich binnen het kritieke gebied bevindt, dan wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard.</li> <li>Als de toetsingsgrootheid zich niet in het kritieke maar in het aanvaardingsgebied bevindt, dan wordt de nulhypothese niet verworpen.</li> </ul> <p>Merk op dat deze twee methoden equivalent zijn en je dus in de praktijk niet beide moet uitvoeren. In de wetenschappelijke literatuur wordt meestal de overschrijdingskans gebruikt en ook expliciet gerapporteerd.</p> <p>Statistische toetsen die in deze cursus besproken worden:</p> <ul> <li>de z-toets</li> <li>de t-toets</li> <li>de t-toets voor twee steekproeven</li> <li>de chi-kwadraat aanpassingstoets</li> <li>de chi-kwadraattoets voor onafhankelijkheid</li> </ul>"},{"location":"nl/interkwartielafstand/","title":"interkwartielafstand (IQR)","text":"<p>(EN: interquartile range)</p> <p>De interkwartielafstand (IQR) van een steekproef of populatie wordt berekend als:</p> \\[ IQR = | Q_3 - Q_1 | \\] <p>Met \\(Q_3\\) het derde kwartiel en \\(Q_1\\) het eerste kwartiel.</p> <p>Tussen \\(Q_1\\) en \\(Q_3\\) liggen 50% van de waarnemingen in de steekproef.</p> <p>De interkwartielafstand is een spreidingsmaat voor kwantitatieve variabelen. Ze is minder gevoelig voor uitschieters dan de standaardafwijking en is daardoor beter geschikt dan de standaardafwijking voor variabelen die niet normaal verdeeld zijn.</p>"},{"location":"nl/kans/","title":"kans, waarschijnlijkheid","text":"<p>(EN: probability)</p> <p>Een kans, waarschijnlijkheid of probabiliteit is een getal dat aangeeft hoe waarschijnlijk het is dat een bepaalde gebeurtenis zich tijdens een experiment zal voordoen. In andere woorden, de waarschijnlijkheid vertegenwoordigt de relatieve frequentie van het optreden van de gebeurtenis bij het uitvoeren van een groot aantal (onafhankelijke) experimenten.</p>"},{"location":"nl/kans/#universum-uitkomstenruimte","title":"universum, uitkomstenruimte","text":"<p>De verzameling van alle mogelijke uitkomsten van een gebeurtenis noemen we de uitkomstenruimte of het universum, genoteerd als \\(\\Omega\\) (Griekse hoofdletter Omega).</p> <p>Gebeurtenissen zijn deelverzamelingen van \\(\\Omega\\) en worden typisch genoteerd als een hoofdletter (vb. \\(A, B, \\ldots\\)).</p>"},{"location":"nl/kans/#axiomas-van-de-kansrekening","title":"axioma's van de kansrekening","text":"<p>Kansen moeten voldoen aan volgende voorwaarden:</p> <ol> <li>Kansen zijn niet negatief: \\(P(A) \\geq 0\\) for each \\(A\\)</li> <li>Het universum heeft kans 1: \\(P(\\Omega) = 1\\)</li> <li> <p>Somregel: als \\(A\\) en \\(B\\) disjuncte gebeurtenissen zijn (d.w.z. \\(A \\cap B = \\emptyset\\)), dan geldt:</p> <p>\\(P(A\\cup B) = P(A) + P(B).\\)</p> </li> </ol>"},{"location":"nl/kans/#eigenschappen","title":"eigenschappen","text":"<p>Uit de drie axioma's kunnen we alle eigenschappen van kansen afleiden. Enkele belangrijke:</p> <ul> <li> <p>Complementregel: Voor elke gebeurtenis \\(A\\) geldt:</p> <p>\\(P(\\overline{A}) = 1  - P(A)\\)</p> <p>met \\(\\overline{A} = \\Omega \\setminus A\\), de kans dat gebeurtenis \\(A\\) zich NIET voordoet.</p> </li> <li> <p>De onmogelijke gebeurtenis heeft kans 0:</p> <p>\\(P(\\emptyset) = 0\\)</p> </li> <li> <p>De algemene somregel: Voor elke gebeurtenis \\(A\\) en \\(B\\) geldt:</p> <p>\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\)</p> </li> </ul>"},{"location":"nl/kans/#onafhankelijke-gebeurtenissen","title":"onafhankelijke gebeurtenissen","text":"<p>Twee gebeurtenissen zijn onafhankelijk als en slechts als:</p> <p>\\(P(A \\cap B) = P(A)P(B)\\)</p>"},{"location":"nl/kans/#voorwaardelijke-kans","title":"voorwaardelijke kans","text":"<p>De kans dat gebeurtenis \\(A\\) zich voordoet op voorwaarde dat gebeurtenis \\(B\\) zich voordoet, noteren we met \\(P(A|B)\\)</p>"},{"location":"nl/kansverdeling/","title":"kansverdeling","text":"<p>(EN: probability distribution)</p> <p>Ook: waarschijnlijkheidsverdeling, of -distributie.</p> <p>De kansverdeling van een stochastische variabele \\(X\\) is een wiskundige functie die de kans geeft dat een bepaalde uitkomst van \\(X\\) zich voordoet.</p> <p>Er wordt onderscheid gemaakt tussen enerzijds discrete en continue verdelingen. De kansverdeling van een discrete variabele wordt beschreven door een kansfunctie (EN: probability mass function), die van een continue variabele door een kansdichtheidsfunctie (EN: probability distribution function).</p>"},{"location":"nl/kansverdeling/#kansfunctie","title":"Kansfunctie","text":"<p>(EN: probability mass function)</p> <p>Bij een discrete stochastische variabele kan je voor elke mogelijke uitkomst \\(x\\) de kans \\(P(X = x)\\) opsommen.</p> <p>Voorbeeld: het aantal ogen bij twee dobbelstenen is een discrete stochastische variabele met waarden \\(2, 3, \\ldots, 12\\). De kansverdeling van deze variabele is:</p> \\(x\\) 2 3 4 5 6 7 8 9 10 11 12 \\(P(X = x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 <p>Of, compacter uitgedrukt:</p> \\[P(X = x) = \\frac{min(x-1, 13-x)}{36}\\] <p>Deze functie voldoet aan de axioma's van de kansrekening:</p> <ul> <li>\\(\\forall x: 0 \\leq P(X = x) \\leq 1\\)</li> <li>\\(\\sum_x P(X = x) = 1\\)</li> <li>Ook de somregel werkt, bv. de kans dat je een even getal gooit is \\(P(X = 2) + P(X = 4) + \\ldots + P(X = 12) = 18/36 = 1/2\\).</li> </ul> <p>De verwachtingswaarde (of verwachte waarde; EN: expecation, expected value) van een discrete stochastische variabele, genoteerd \\(\\mu_X\\) of \\(E(X)\\) is:</p> \\[\\mu_X = \\sum_x x \\cdot P(X = x) = \\sum_x x \\cdot f_X(x)\\] <p>De variantie (EN: variance) van een discrete stochastische variabele, genoteerd \\(\\sigma_X^2\\) is:</p> \\[\\sigma_X^2 = \\sum_x (x - \\mu_X)^2 \\cdot P(X = x) = \\sum_x (x - \\mu_X)^2 \\cdot f_X(x)\\] <p>De standaardafwijking (EN: standard deviation) van een discrete stochastische variabele, genoteerd \\(\\sigma_X\\) is dan de vierkantswortel van de variantie:</p> \\[\\sigma_X = \\sqrt{\\sigma_X^2}\\]"},{"location":"nl/kansverdeling/#kansdichtheidsfunctie","title":"Kansdichtheidsfunctie","text":"<p>(EN: probability density function)</p> <p>Bij een continue stochastische variabele die elke re\u00eble waarde als uitkomst kan hebben, is het niet mogelijk om voor elke mogelijke uitkomst \\(x\\) de kans \\(P(X = x)\\) op te sommen. Hier geldt dat voor elke \\(x\\) de kans \\(P(X = x) = 0\\). In plaats daarvan wordt de kansverdeling beschreven door een functie die de kans geeft dat een bepaalde uitkomst \\(x\\) zich voordoet in een bepaald interval \\([a, b] \\subset \\mathbb{R}\\).</p> <p>Het uitwerken van de volledige formele wiskundige basis van continue verdelingen valt buiten het bereik van deze cursus. De eigenschappen van een discrete kansverdeling blijven echter gelden:</p> <ul> <li> <p>De som van alle kansen is 1, wat overeenkomt met de totale oppervlakte van het gebied tussen de X-as en de kansdichteidsfunctie \\(f\\).</p> \\[\\int_{-\\infty}^{+\\infty} f(x) \\mathrm{d}x = 1\\] </li> <li> <p>De kans dat een continue stochastische variabele \\(X\\) in een bepaald interval \\([a, b]\\) valt is \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x) \\, \\mathrm{d}x\\) en die kans is altijd tussen \\(0\\) en \\(1\\).</p> \\[0 \\leq \\int_{a}^{b} f(x) \\mathrm{d}x \\leq 1\\] </li> <li> <p>De complementregel geldt ook, dus \\(P(X \\leq a) = 1 - P(X \\geq a)\\).</p> \\[\\int_{-\\infty}^{a} f(x) \\mathrm{d}x = 1 - \\int_{a}^{+\\infty} f(x) \\mathrm{d}x\\] </li> </ul> <p>Een kans $P(X \\leq a) noemen we ook een linkerstaartkans, \\(P(X \\geq a)\\) een rechterstaartkans.</p>"},{"location":"nl/kansverdeling/#bekende-kansverdelingen","title":"Bekende kansverdelingen","text":"<p>We sommen hier de kansverdelingen op die in deze cursus aan bod komen. Voor een uitgebreidere lijst, zie bv. Wikipedia.</p> <ul> <li>De normale verdeling</li> <li>De t-verdeling</li> <li>De uniforme verdeling</li> <li>De \\(\\chi^2\\) verdeling (chi-kwadraat)</li> </ul>"},{"location":"nl/kdediagram/","title":"kerndichtheidsschattingsdiagram","text":"<p>(EN: kernel density estimation plot)</p>"},{"location":"nl/kritieke-gebied/","title":"kritieke gebied","text":"<p>(EN: critical region)</p> <p>In de context van hypothesetoetsen is het kritieke gebied de verzameling van alle mogelijke waarden voor de toetsingsgrootheid waarvoor we de nulhypothese zullen verwerpen.</p> <p>Of, met andere woorden, dit is de verzameling van alle waarden voor de toetsingsgrootheid waarvoor de overschrijdingskans kleiner is dan of gelijk aan het significantieniveau.</p> <p>De waarden waarvoor we de nulhypothese niet verwerpen, vormen het aanvaardingsgebied.</p>"},{"location":"nl/kritieke-grenswaarde/","title":"kritieke grenswaarde","text":"<p>(EN: critical value)</p> <p>In de context van hypothesetoetsen is de kritieke grenswaarde de waarde voor een toetsingsgrootheid die op de grens ligt tussen het kritieke gebied en het aanvaardingsgebied.</p> <p>Meer bepaald is dit een waarde waarvan de overschrijdingskans \\(p\\) gelijk is aan het significantieniveau \\(\\alpha\\).</p>"},{"location":"nl/kruistabel/","title":"kruistabel","text":"<p>(EN: contingency table)</p> <p>Een kruistabel is een tabel die de frequenties van de combinatie van de waarden van twee kwalitatieve variabelen samenvat.</p> <p>De conventie is om de waarden van de onafhankelijke variabele in de kolommen te zetten en de waarden van de afhankelijke variabele in de rijen.</p> <p>Een kruistabel kan aangevuld worden met de som van elke rij of kolom. Dit noemen we marginalen of marginale totalen.</p>"},{"location":"nl/kruistabel/#voorbeeld","title":"Voorbeeld","text":"Female Male Strongly disagree 0 4 Disagree 17 45 Neutral 23 91 Agree 12 53 Strongly agree 0 5 <ul> <li>De waarden van de onafhankelijke variabele <code>Gender</code> staan in de kolommen: <code>Female</code> en <code>Male</code>.</li> <li>De waarden van de afhankelijke variabele <code>Survey</code> staan in de rijen: <code>Strongly disagree</code>, <code>Disagree</code>, <code>Neutral</code>, <code>Agree</code> en <code>Strongly agree</code>.</li> <li>De getallen in de cellen zijn de waargenomen (geobserveerde) frequenties van de combinaties van de waarden van de twee variabelen.</li> </ul> <p>Met toegevoegde marginalen:</p> Female Male Total Strongly disagree 0 4 4 Disagree 17 45 62 Neutral 23 91 114 Agree 12 53 65 Strongly agree 0 5 5 Total 52 198 250 <ul> <li>Het totaal aantal observaties \\(n = 250\\).</li> </ul>"},{"location":"nl/marginalen/","title":"marginalen","text":"<p>(EN: marginals)</p> <p>Marginalen of marginaaltotalen zijn de totalen van de rijen of kolommen van een kruistabel.</p>"},{"location":"nl/mediaan/","title":"mediaan","text":"<p>(EN: median)</p> <p>De mediaan van een steekproef of populatie is de waarde die de lagere helft van de waarden en de hogere helft van elkaar scheidt.</p> <p>Je kan de mediaan bepalen door de waarden te sorteren en (bij een oneven aantal) de middelste waarde te nemen, of (bij een even aantal) het gemiddelde van de twee middelste waarden.</p> <p>De mediaan kan worden gebruikt bij kwantitatieve variabelen of ordinale.</p> <p>De spreidingsmaat die vaak samen met deze centrummaat gebruikt wordt is de interkwartielafstand.</p>"},{"location":"nl/meetniveau/","title":"meetniveau","text":"<p>(EN: level of measurement)</p> <p>Onder het meetniveau van een variabele verstaan we het variabeletype. In de statistiek onderscheiden we volgende niveaus:</p> <ul> <li>Kwalitatieve (ook: categorische, discrete) variabelen<ul> <li>Nominaal</li> <li>Ordinaal</li> </ul> </li> <li>Kwantitatieve (ook: continue) variabelen<ul> <li>Interval</li> <li>Ratio</li> </ul> </li> </ul> <p>Van het meetniveau hangt af welke de meest geschikte statistische technieken zijn om deze variabelen te onderzoeken en te interpreteren.</p>"},{"location":"nl/meetniveau/#kwalitatieve-variabelen","title":"Kwalitatieve variabelen","text":"<p>Wat typisch is aan kwalitatieve variabelen is dat er meestal een beperkt aantal mogelijke waarden zijn en dat deze waarden niet noodzakelijk numeriek zijn.</p>"},{"location":"nl/meetniveau/#nominale-schaal","title":"Nominale schaal","text":"<p>Variabelen waarvan we de waarden enkel kunnen opsommen of benoemen, zonder dat er een logische of inherente volgorde tussen bestaat, noemen we nominaal.</p> <p>Voorbeelden van nominale variabelen:</p> <ul> <li>gender (man, vrouw, nonbinair, ...)</li> <li>politieke partij</li> <li>land waarin je woont</li> </ul> <p>Merk op dat in sommige datasets de waarde van een nominale variabele kan voorgesteld worden door getallen (bv. 0 = overleden, 1 = overleefd). Dat verandert echter niets aan het meetniveau.</p>"},{"location":"nl/meetniveau/#ordinale-schaal","title":"Ordinale schaal","text":"<p>Ordinale variabelen zijn kwalitatieve variabelen waar er w\u00e9l een inherente volgorde tussen de waarden bestaat.</p> <p>Voorbeelden van ordinale variabelen:</p> <ul> <li>Opleidingsniveau (kleuter, lager, lager secundair, hoger secundair, hoger beroepsonderwijs, bachelor, master, doctoraat)</li> <li>Likert-schaal (helemaal oneens, oneens, geen mening, eens, helemaal eens)</li> <li>Beoordeling (onvoldoende, voldoende, met onderscheiding, met grote onderscheiding, met grootste onderscheiding)</li> </ul>"},{"location":"nl/meetniveau/#kwantitatieve-variabelen","title":"Kwantitatieve variabelen","text":"<p>Kwantitatieve variabelen drukken een hoeveelheid (kwantiteit) uit en zijn altijd numeriek. Men moet ook altijd aangeven in welke meeteenheid deze numerieke waarde is uitgedrukt.</p> <p>Het is best mogelijk dat elke observatie een unieke waarde is binnen de steekproef, of in elk geval verwacht je veel verschillende waarden.</p>"},{"location":"nl/meetniveau/#intervalschaal","title":"Intervalschaal","text":"<p>Een grootheid op intervalschaal heeft geen vast nulpunt, maar men is eerder ge\u00efnteresseerd in verschillen tussen twee waarden.</p> <p>Een typisch voorbeeld van een intervalschaal is de temperatuur in \u02daC. Het verschil tussen 10\u02daC en 20\u02daC is hetzelfde als tussen 13\u02daC en 23\u02daC.</p> <p>Doordat er geen vast nulpunt is, kan je ook niet rekenen met verhoudingen. Het is dus niet zo dat een temperatuur van 20\u02daC het dubbele is van 10\u02daC. Als je beide waarden zou omzetten naar \u02daF (nl. resp. 50\u02daF en 68\u02daF) dan klopt de verhouding ook niet meer.</p> <p>Voorbeelden:</p> <ul> <li>Temperatuur (\u02daC, \u02daF)</li> <li>Datum, tijdstip, timestamp (Unix time, gregoriaanse kalender, Islamitische kalender, ...)</li> </ul>"},{"location":"nl/meetniveau/#ratioschaal","title":"Ratioschaal","text":"<p>Bij een ratioschaal heb je ook een numerieke waarde en een meeteenheid, maar er is ook sprake van een duidelijk en vast nulpunt. Daardoor kan je ook met verhoudingen (Latijn en Engels: ratio) rekenen.</p> <p>Voorbeelden zijn:</p> <ul> <li>Massa (g, kg, ...)</li> <li>Afstand (mm, cm, m, km, ...)</li> <li>Oppervlakte (m\u00b2, ca, a, ha, ...)</li> <li>Energie (J)</li> <li>Leeftijd (j)</li> <li>Tijdsduur (ms, s, min, u, ...)</li> <li>Temperatuur (\u02daK)</li> </ul> <p>Een afstand tussen twee objecten kan niet negatief zijn, dus er is duidelijk sprake van een absoluut nulpunt. Als de afstand tussen twee voorwerpen 100cm is en tussen twee andere 150cm, dan is die tweede afstand 50% groter.</p> <p>Temperatuur in Kelvin is w\u00e9l een ratioschaal want 0\u02daK is het absolute nulpunt. Als de temperatuur uitgedrukt in Kelvin verdubbelt, verdubbelt ook de aanwezige energie.</p>"},{"location":"nl/modus/","title":"modus","text":"<p>(EN: mode)</p> <p>De modus van een (kwalitatieve) variabele is de waarde die het vaakst voorkomt in de steekproef.</p> <p>In principe kan je ook de modus berekenen van een kwantitatieve variabele, maar dat is meestal niet zinvol.</p>"},{"location":"nl/mozaiekdiagram/","title":"mozaiekdiagram","text":"<p>(EN: mosaic diagram)</p> <p>Een moza\u00efekdiagram is een grafische voorstelling van een kruistabel die de relatieve frequenties van de verschillende combinaties van de waarden van twee (of meer) categorische variabelen toont.</p> <p>De breedte van de rechthoeken in het diagram is evenredig met de relatieve frequentie van de waarden van de eerste variabele, en de hoogte is evenredig met de relatieve frequentie van de waarden van de tweede variabele. De oppervlakte van elk rechthoek is dus evenredig met de relatieve frequentie van de combinatie van waarden van beide variabelen.</p> <p></p> <p>De onafhankelijke variabele wordt typisch op de x-as weergegeven en de afhankelijke op de y-as.</p>"},{"location":"nl/normale-verdeling/","title":"normale verdeling","text":"<p>(EN: normal distribution)</p> <p>De normale verdeling is een continue kansverdeling met twee parameters: de verwachtingswaarde \\(\\mu\\) en de standaardafwijking \\(\\sigma\\).</p> <p>De normale verdeling met verwachtingswaarde \\(\\mu = 0\\) en standaardafwijking \\(\\sigma = 1\\) noemen we de standaardnormaalverdeling.</p> <p>Als een stochastische variabele \\(X\\) een normale verdeling heeft met verwachtingswaarde \\(\\mu\\) en standaardafwijking \\(\\sigma\\), dan schrijven we \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\).</p> <p>De kansdichtheidsfunctie ziet er als volgt uit:</p> <p></p> <p>De cumulatieve kansdichtheidsfunctie (of linkerstaartkans) ziet er als volgt uit:</p> <p></p>"},{"location":"nl/notatie/","title":"notatie","text":"<p>(EN: notation)</p>"},{"location":"nl/notatie/#steekproef-en-populatie","title":"Steekproef en populatie","text":"Steekproef Populatie Grootte \\(n\\) \\(N\\) Gemiddelde \\(\\overline{x}\\) \\(\\mu\\) Variantie \\(s^2\\) \\(\\sigma^2\\) Standaardafwijkking \\(s\\) \\(\\sigma\\)"},{"location":"nl/notatie/#waarschijnlijkheidsleer","title":"Waarschijnlijkheidsleer","text":"<p>Zie ook kans.</p> Symbool Betekenis \\(\\Omega\\) universum \\(A, B, \\ldots\\) gebeurtenissen (met \\(A \\subset \\Omega\\), \\(B \\subset \\Omega\\), enz.) \\(P(A)\\) de kans op gebeurtenis \\(A\\) (met \\(0 \\leq P(A) \\leq 1\\)) \\(P(A|B)\\) de kans op \\(A\\) als \\(B\\) zich voordoet"},{"location":"nl/notatie/#de-normale-verdeling","title":"De normale verdeling","text":"<ul> <li>\\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\)<ul> <li>De stochastische variabele \\(X\\) heeft een normale verdeling heeft met verwachtingswaarde \\(\\mu\\) en standaardafwijking \\(\\sigma\\).</li> </ul> </li> <li>\\(Z \\sim \\mathcal{N}(0, 1)\\)<ul> <li>De standaardnormale verdeling.</li> </ul> </li> <li>\\(M \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\\)<ul> <li>De kansverdeling van het steekproefgemiddelde (zie de centrale limietstelling).</li> </ul> </li> </ul>"},{"location":"nl/notatie/#statistische-toetsen","title":"Statistische toetsen","text":"<ul> <li>\\(H_0\\) - de nulhypothese</li> <li>\\(H_1\\) - de alternatieve hypothese</li> <li>\\(\\alpha\\) - het significantieniveau</li> </ul>"},{"location":"nl/nulhypothese/","title":"nulhypothese","text":"<p>(EN: null hypothesis)</p> <p>In de context van hypothesetoetsen is nulhypothese (vaak genoteerd als \\(H_0\\)) een veronderstelling over een populatieparameter die we willen testen.</p> <p>De nulhypothese stelt typisch de veronderstelling voor dat er geen significant verschil is tussen de populatieparameter en een bepaalde waarde, of dat er geen verband bestaat tussen twee variabelen.</p> <p>De procedure van de toets is gebaseerd op de veronderstelling dat de nulhypothese waar is. Als we dan op een tegenspraak stuiten, wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard.</p>"},{"location":"nl/overschrijdingskans/","title":"overschrijdingskans","text":"<p>(EN: p-value)</p> <p>De overschrijdingskans (ook wel p-waarde genoemd) is de kans dat de waarde van de toetsingsgrootheid (of \u00e9\u00e9n die minstens zo extreem is) kan bekomen worden als de nulhypothese waar is.</p> <p>Wanneer de overschrijdingskans kleiner is dan het vooraf gekozen significantieniveau, of \\(p \\leq \\alpha\\), dan wordt de nulhypothese verworpen en wordt de alternatieve hypothese aanvaard. Als \\(p &gt; \\alpha\\) dan wordt de nulhypothese niet verworpen.</p>"},{"location":"nl/percentiel/","title":"percentiel","text":"<p>(EN: percentile)</p> <p>Een percentiel van een geordende reeks waarnemingen is een van de in principe 99 punten die de reeks verdeelt in 100 delen van gelijke grootte. Het \\(k\\)-de percentiel is dan een getal waarbij \\(k\\)% van de waarnemingen kleiner zijn en \\((100-k)\\)% groter zijn dan dat getal.</p>"},{"location":"nl/percentiel/#kwartiel","title":"kwartiel","text":"<p>De kwartielen worden gevormd uit vijf specifieke percentielen die de dataset in vier gelijke delen verdelen:</p> <ul> <li>\\(\\min\\), het minimum, of percentiel 0</li> <li>\\(Q_1\\), het eerste kwartiel of percentiel 25</li> <li>\\(Q_2\\), de mediaan, of percentiel 50</li> <li>\\(Q_3\\), het derde kwartiel of percentiel 75</li> <li>\\(\\max\\), het maximum, of percentiel 100</li> </ul> <p>Het verschil tussen de grootste en kleinste waarde wordt bereik genoemd, en tussen het derde en eerste kwartiel de interkwartielafstand.</p>"},{"location":"nl/populatie/","title":"populatie","text":"<p>(EN: population)</p> <p>Een populatie is een groep van objecten die onderzocht worden. In veel gevallen is het niet praktisch haalbaar om het onderzoek op elk individu uit te voeren. In zo'n gevallen wordt er een steekproef genomen.</p>"},{"location":"nl/puntschatter/","title":"puntschatter","text":"<p>(EN: point estimate)</p> <p>Een puntschatter is waarde berekend uit een steekproef die een onbekende populatieparameter zo goed mogelijk probeert te benaderen.</p> <p>De formule voor de steekproefstandaardafwijking \\(s\\) is een puntschatter voor de (onbekende) populatiestandaardafwijking \\(\\sigma\\).</p> <p>Een schatter wordt soms genoteerd als \\(\\hat{\\theta}\\), waarbij \\(\\theta\\) een onbekende populatieparameter is.</p> <p>Zie ook: betrouwbaarheidsinterval</p>"},{"location":"nl/residuen-gestandaardiseerde/","title":"residuen, gestandaardiseerde","text":"<p>(EN: residuals, standardized)</p> <p>Gestandaardiseerde residu\u00ebn vormen een maat om in een frequentie- of kruistabel te bepalen of deze categorie over- of ondervertegenwoordigd is in de steekproef.</p> <p>Een residu is het verschil tussen de geobserveerde en de verwachte waarde. Het standaardiseren houdt in dat de resulterende waarde niet afhangt van de grootorde van de frequenties, van de steekproefgrootte, of van de grootte van de frequentie- of kruistabel.</p> \\[ r_i = \\frac{o_i-e_i}{\\sqrt{e_i (1-\\pi_i)}} \\] <p>Hierbij is:</p> <ul> <li>\\(i\\) = index van de categorie</li> <li>\\(r_i\\) = gestandaardiseerd residu van categorie \\(i\\)</li> <li>\\(o_i\\) = geobserveerde frequentie</li> <li>\\(e_i\\) = verwachte frequentie</li> <li>\\(\\pi_i\\) = proportie van de \\(i\\)-de categorie in de steekproef (relatieve frequentie)</li> </ul> <p>Je kan de waarde \\(r_i\\) als volgt interpreteren:</p> <ul> <li>Als \\(r_i &lt; -2\\), dan is de categorie \\(i\\) ondervertegenwoordigd in de steekproef.</li> <li>Als \\(-2 \\leq r_i \\leq 2\\), dan is de categorie \\(i\\) evenredig vertegenwoordigd in de steekproef.</li> <li>Als \\(r_i &gt; 2\\), dan is de categorie \\(i\\) oververtegenwoordigd in de steekproef.</li> </ul>"},{"location":"nl/significantieniveau/","title":"significantieniveau","text":"<p>(EN: significance level)</p> <p>In de context van hypothesetoetsen is het significantieniveau (\\(\\alpha\\)) de kans dat de nulhypothese ten onrechte verworpen wordt.</p> <p>Het significantieniveau is gerelateerd aan het betrouwbaarheidsniveau (\\(1 - \\alpha\\)) van een betrouwbaarheidsinterval.</p>"},{"location":"nl/spreidingsdiagram/","title":"spreidingsdiagram","text":"<p>(EN: scatter plot)</p> <p>TODO</p>"},{"location":"nl/spreidingsmaat/","title":"spreidingsmaat","text":"<p>(EN: measure of dispersion)</p> <p>Een spreidingsmaat drukt uit in hoeverre waarden in een steekproef of populatie van elkaar verschillen.</p> <p>Er bestaan verschillende manieren om een spreidingsmaat te bepalen, wij zullen er slechts enkele gebruiken in deze cursus. De besproken spreidingsmaten zijn enkel geschikt voor kwantitatieve variabelen.</p> <ul> <li>variantie en standaardafwijking</li> <li>interkwartielafstand en bereik</li> </ul> <p>Samen met een centrummaat vormt een spreidingsmaat een manier om de karakteristieken van waarnemingen voor een variabele uit te drukken.</p>"},{"location":"nl/staafdiagram/","title":"staafdiagram","text":"<p>(EN: bar chart)</p> <p>Een staafdiagram is een grafiektype dat de frequenties van de waarden van een kwalitatieve variabele weergeeft met behulp van rechthoeken. De hoogte van een staaf stelt de frequentie van de corresponderende waarde voor.</p> <p>Met een eenvoudig staafdiagram kan je \u00e9\u00e9n enkele variabele visualiseren. Om twee variabelen tegelijkertijd te visualiseren, kan je gebruik maken van een geclusterd staafdiagram, een rependiagram of een moza\u00efekdiagram.</p>"},{"location":"nl/staafdiagram/#geclusterd-staafdiagram","title":"Geclusterd staafdiagram","text":"<p>In een geclusterd staafdiagram worden meerdere staafdiagrammen gecombineerd. De staafdiagrammen worden gegroepeerd per waarde van de afhankelijke variabele, die op de X-as wordt weergegeven. Onderscheid tussen de onafhankelijke variabele wordt meestal gemaakt door kleur of arcering van de staven.</p> <p>Voorbeeld:</p> <p></p> <ul> <li>De onafhankelijke variabele <code>Gender</code> wordt weergegeven met de kleuren. Blauwe staven zijn voor <code>Female</code>, oranje staven voor <code>Male</code>.</li> <li>De afhankelijke variabele <code>Survey</code> wordt weergegeven met de X-as. De staven worden gegroepeerd per waarde van <code>Survey</code>.</li> <li>Als de \"vorm\" van de staven in de verschillende kleuren ongeveer gelijk zijn, dan is dit een aanwijzing dat er geen verband is tussen de twee variabelen. Als er grote verschillen zijn (bv. andere modus, waarden die voor de ene variabele voorkomen en niet voor de andere, ...) dan is dit een aanwijzing dat er wel een verband is tussen de twee variabelen.</li> <li>Als er grote verschillen zijn in het aantal observaties voor elke waarde van de onafhankelijke variabele, of als er een groot aantal mogelijke waarden zijn voor de onafhankelijke variabele, dan is het niet zo eenvoudig om af te leiden in hoeverre er een verband is. In deze grafiek is dat inderdaad het geval: er zijn veel minder observaties voor <code>Female</code> dan voor <code>Male</code>. Om dit probleem op te lossen, kan je gebruik maken van een rependiagram.</li> </ul>"},{"location":"nl/staafdiagram/#rependiagram","title":"Rependiagram","text":"<p>In een rependiagram worden de staven niet geclusterd, maar gestapeld. Bovendien worden de totalen genormaliseerd. Op die manier kan je de verhouding tussen de waarden van de onafhankelijke variabele beter inschatten.</p> <p>Voorbeeld:</p> <p></p> <ul> <li>De onafhankelijke variabele <code>Gender</code> wordt weergegeven op de Y-as</li> <li>De afhankelijke variabele <code>Survey</code> wordt weergegeven op de X-as, elke waarde wordt vertegenwoordigd door een kleur.</li> <li>Om de onderlinge verschillen in de verhoudingen tussen beide groepen duidelijker te maken, is het totaal van elke groep genormaliseerd tot 100%. De hoogte van de gekleurde vlakken stelt dus de verhouding voor, niet het absolute aantal observaties.</li> <li>Als de grenzen tussen de kleurvlakken ongeveer op dezelfde hoogte liggen, dan is dit een aanwijzing dat er geen verband is tussen de twee variabelen. Als er grote verschillen zijn, dan is dit een aanwijzing dat er wel een verband is tussen de twee variabelen.<ul> <li>In dit diagram zien we dat de grenzen tussen de kleurvlakken niet helemaal op dezelfde hoogte liggen, maar in grote lijnen komen gelijkaardige verhoudingen terug. Dit is een aanwijzing dat er geen of slechts een zwak verband is tussen de twee variabelen.</li> </ul> </li> <li>Merk op dat je een rependiagram ook verticaal kan weergeven, maar dan moet je er wel voor zorgen dat het voldoende groot geplot wordt. Anders is het moeilijk om de verschillen in de verhoudingen in te schatten.</li> <li>Bij een rependiagram zien we niet dat er meer observaties voor <code>Male</code> zijn dan voor <code>Female</code>. Een moza\u00efekdiagram kan dit probleem oplossen. Het behoudt de eigenschappen van een rependiagram, maar toont ook het aantal observaties van de onafhankelijke variabele.</li> </ul>"},{"location":"nl/standaardfout/","title":"standaardfout","text":"<p>(EN: standard error)</p> <p>In de context van de Centrale Limietstelling is de standaardfout gedefinieerd als de standaardafwijking gedeeld door de vierkantswordel van de steekproefgrootte:</p> \\[\\text{SE} = \\frac{\\sigma}{\\sqrt{n}}\\] <p>Deze waarde speelt een rol bij het bepalen van betrouwbaarheidsintervallen.</p>"},{"location":"nl/steekproef-aselecte/","title":"steekproef, aselecte","text":"<p>(EN: random sample)</p> <p>Een steekproef is aselect wanneer elk individu in de populatie evenveel kans heeft om geselecteerd te worden in een steekproef.</p>"},{"location":"nl/steekproef-representatieve/","title":"steekproef, representatieve","text":"<p>(EN: sample, representative)</p> <p>Een steekproef is representatief wanneer de eigenschappen van de populatie ook gereflecteerd worden binnen de steekproef.</p> <p>Bijvoorbeeld, als in een populatie 53% zichzelf identificeren als vrouw, 46% als man en 1% als nonbinair, dan wil je als onderzoeker dat deze verhoudingen ook in een steekproef terugkomen.</p> <p>Kleine afwijkingen zijn daarbij wel aanvaardbaar. Een onderzoeker kan dit controleren aan de hand van een chi-kwadraat aanpassingstoets.</p>"},{"location":"nl/steekproef/","title":"steekproef","text":"<p>(EN: sample)</p> <p>Een steekproef is een deelverzameling uit een populatie waarop het onderzoek wordt uitgevoerd.</p> <p>Onder bepaalde omstandigheden mag je veronderstellen dat resultaten bekomen in de steekproef ook gelden voor de populatie als geheel.</p> <p>Een goede steekproef voldoet aan enkele eigenschappen:</p> <ul> <li>de steekproef is aselect</li> <li>de steekproef is voldoende groot</li> <li>de steekproef is representatief voor de populatie</li> </ul> <p>In het ideale geval gaat een onderzoeker als volgt te werk voor het trekken van een steekproef uit een populatie:</p> <ul> <li>eerst en vooral moet de populatie goed gedefinieerd zijn</li> <li>dan kan je een steekproefkader opstellen, d.w.z. een lijst van alle individu\u00ebn in een populatie</li> <li>vervolgens kiest de onderzoeker aselect een aantal individu\u00ebn uit</li> </ul> <p>Vaak is het moeilijk of onmogelijk om een steekproefkader op te stellen. In zo'n gevallen kiest de onderzoeker een andere steekproefmethode en probeert zoveel mogelijk de hierboven opgesomde eigenschappen te benaderen binnen de beschikbare tijd en budget.</p> <p>Zelfs onder de beste omstandigheden zal het resultaat binnen een steekproef wellicht afwijken van de \"echte\" waarde in de populatie, hoewel we hopen dat we deze voldoende kunnen benaderen. Door het nemen van een steekproef introduceren we dus fouten.</p>"},{"location":"nl/steekproeffouten/","title":"steekproeffouten","text":"<p>(EN: sampling errors)</p> <p>Wanneer onderzoekers een populatie onderzoeken op basis van een steekproef, dan worden er sowieso fouten gemaakt, d.w.z. dat resultaten van metingen en analyses binnen de steekproef niet zullen overeenkomen met de werkelijke waarde over de gehele populatie.</p> <p>De manier waarop we een steekproef nemen kan invloed hebben op de resultaten.</p>"},{"location":"nl/steekproeffouten/#steekproeffout","title":"steekproeffout","text":"<p>We kunnen te maken hebben met willekeurige of systematische steekproeffouten:</p>"},{"location":"nl/steekproeffouten/#willekeurige-steekproeffout","title":"willekeurige steekproeffout","text":"<p>Willekeurige steekproeffouten zijn enkel aan het toeval te wijten en kan je niet vermijden. Telkens je een aselecte steekproef neemt, zal je binnen die steekproef een ander resultaat krijgen.</p>"},{"location":"nl/steekproeffouten/#systematische-steekproeffout","title":"systematische steekproeffout","text":"<p>Een systematische steekproeffout is erger, want kan er voor zorgen dat de resultaten vertekend zijn en dus niet meer representatief voor de populatie. Voorbeelden van systematische steekproeffouten:</p> <ul> <li>In een online enqu\u00eate worden enkel personen met toegang tot internet geselecteerd. Deze steekproef is dus niet meer aselect.</li> <li>Als je een enqu\u00eate afneemt waar mensen vrijwillig aan deelnemen, dan heb je meer kans dat mensen deelnemen die ook in het onderwerp ge\u00efnteresseerd zijn. Dat kan ook impact hebben op de resultaten.</li> </ul>"},{"location":"nl/steekproeffouten/#niet-steekproeffout","title":"niet-steekproeffout","text":"<p>Na het nemen van de steekproef kunnen ook fouten gemaakt worden bij het meten en analyseren. In dit geval spreken we van niet-steekproeffouten en ook hier maken we onderscheid tussen willekeurige en systematische:</p>"},{"location":"nl/steekproeffouten/#willekeurige-niet-steekproeffout","title":"willekeurige niet-steekproeffout","text":"<p>Hieronder plaatsen we gevallen waar bv. een respondent per ongeluk een verkeerd antwoord selecteert of invult in een enqu\u00eate.</p>"},{"location":"nl/steekproeffouten/#systematische-niet-steekproeffout","title":"systematische niet-steekproeffout","text":"<p>Voorbeelden:</p> <ul> <li>een meettoestel is verkeerd geijkt en geeft systematisch een iets hogere waarde dan de werkelijkheid</li> <li>respondenten onder- of overschatten intentioneel de werkelijkheid (bv. bij een vraag over hoeveel je dagelijks rookt of alcohol drinkt)</li> </ul>"},{"location":"nl/steekproefgrootte/","title":"steekproefgrootte","text":"<p>(EN: sample size)</p> <p>De steekproefgrootte is het aantal elementen of waarnemingen \\(n\\) in een steekproef.</p>"},{"location":"nl/steekproefkader/","title":"steekproefkader","text":"<p>(EN: sampling frame)</p> <p>Een steekproefkader is een lijst van alle individu\u00ebn die lid zijn van een populatie.</p>"},{"location":"nl/t-toets/","title":"t-toets","text":"<p>(EN: t-test)</p> <p>De t-toets is een statistische hypothesetoets die wordt gebruikt als een alternatief voor de z-toets wanneer de populatiestandaardafwijking \\(\\sigma\\) niet gekend is of wanneer de steekproef te klein is (\\(n&lt;30\\)). De toets wordt ook gebruikt om na te gaan of het gemiddelde van twee steekproeven gelijk is.</p> <p>De voorwaarden voor de t-toets zijn:</p> <ul> <li>de steekproef moet aselect zijn</li> <li>de onderzochte stochastische variabele moet normaal verdeeld zijn</li> </ul>"},{"location":"nl/t-toets/#t-toets-voor-een-steekproef","title":"t-toets voor \u00e9\u00e9n steekproef","text":"<p>De procedure van de t-toets voor \u00e9\u00e9n steekproef verloopt nagenoeg identiek aan die van de z-toets, met als enige verschil dat je in plaats van de normale verdeling gebruik maakt van de Student-t verdeling met \\(n-1\\) vrijheidsgraden. De standaardafwijking van de steekproef wordt gebruikt als schatter van de populatiestandaardafwijking \\(\\sigma\\).</p>"},{"location":"nl/t-toets/#t-toets-voor-twee-steekproeven","title":"t-toets voor twee steekproeven","text":"<p>De t-toets kan ook gebruikt worden om het verschil van de gemiddelden van twee steekproeven te bepalen. We onderscheiden twee gevallen:</p> <ul> <li>Onafhankelijke steekproeven: de twee steekproeven zijn afzonderlijk genomen en de toets beoordeelt of de gemiddelden van de twee steekproeven al dan niet gelijk zijn.</li> <li>Gepaarde steekproeven: voor elke observatie in de eerste steekproef is er een bijbehorende observatie in de tweede steekproef (bijvoorbeeld een keer v\u00f3\u00f3r en een keer na een bepaalde interventie). De toets beoordeelt of het gemiddelde van de verschillen tussen de twee metingen al dan niet gelijk is aan nul.</li> </ul>"},{"location":"nl/t-verdeling/","title":"t-verdeling","text":"<p>Ook: Studentverdeling</p> <p>(EN: t distribution)</p> <p>De t-verdeling (ook: studentverdeling) is een continue kansverdeling die wordt gebruikt in plaats van de normale verdeling wanneer de standaardafwijking van een populatie niet bekend is of als de steekproef niet groot genoeg is.</p> <p>De kansdichtheidsfunctie ziet er uit als die van de normale verdeling, maar is \"platter\" en heeft bredere \"staarten\". De t-verdeling neemt ook de steekproefgrootte \\(n\\) in rekening, via een extra parameter, het aantal vrijheidsgraden of \\(n-1\\).</p> <p></p> <p>De cumulatieve kansdichtheidsfunctie ziet er als volgt uit:</p> <p></p> <p>De \\(t\\)-verdeling werd ontwikkeld door de Engelse statisticus, chemicus en brouwer William Sealy Gosset, die onder het pseudoniem \"Student\" publiceerde. De verdeling werd in 1908 voor het eerst beschreven in een artikel in het tijdschrift Biometrika.</p>"},{"location":"nl/toetsingsgrootheid/","title":"toetsingsgrootheid","text":"<p>(EN: test statistic)</p> <p>In de context van hypothesetoetsen is toetsingsgrootheid een waarde die berekend wordt uit de steekproef om te bepalen of de nulhypothese al dan niet verworpen kan worden.</p>"},{"location":"nl/variabele-stochastische/","title":"stochastische variabele","text":"<p>(EN: random variable)</p> <p>Ook: toevalsvariabele, kansvariabele, stochast</p> <p>Informeel is een stochastische variabele een grootheid waarvan de waarde een re\u00ebel getal is die op de ene of de andere manier afhangt van het toeval. Voorbeelden:</p> <ul> <li>Het aantal gegooide ogen met een dobbelsteen</li> <li>Het nemen van een steekproef uit een populatie</li> <li>De lengte van een persoon</li> <li>...</li> </ul> <p>Formeel wordt een stochastische variabele gedefinieerd als een functie die een re\u00ebel getal toekent aan elke mogelijke uitkomst van een experiment. De verzameling van alle mogelijke uitkomsten van een experiment noemen we het universum of de uitkomstenruimte, genoteerd als \\(\\Omega\\) (Griekse hoofdletter Omega).</p> \\[X: \\Omega \\to \\mathbb{R}: \\omega \\mapsto X(\\omega)\\] <p>Voorbeeld: het aantal gegooide ogen met twee dobbelstenen kan je als volgt formaliseren:</p> \\[X: \\Omega \\to \\mathbb{R}: (a,b) \\mapsto a+b\\] <p>Met \\((a, b) \\in \\Omega = \\{ (1,1), (1,2), \\ldots, (6,6) \\}\\) (= alle mogelijke combinaties van gooien met 2 dobbelstenen). Het waardenbereik van \\(X\\) is dan \\(\\mathbb{R} = \\{2, 3, \\ldots, 12\\}\\).</p> <p>Als het waardenbereik van een stochastische variabele \\(X\\) eindig (zoals in dit voorbeeld) of aftelbaar oneindig is (bv. \\(\\mathbb{N}, \\mathbb{Z}, \\mathbb{Q}\\)), spreken we van een discrete stochastische variabele. Als het waardenbereik overaftelbaar oneindig (bv. \\(\\mathbb{R}, \\mathbb{R^+}\\)) is, spreken we van een continue stochastische variabele.</p> <p>Bij een stochastische variabele \\(X\\) zijn we in het bijzonder ge\u00efnteresseerd in de kansverdeling van \\(X\\).</p>"},{"location":"nl/variantie/","title":"variantie","text":"<p>(EN: variance)</p> <p>De variantie is een spreidingsmaat die bij uitstek geschikt is voor kwantitatieve variabelen die normaal verdeeld zijn.</p> <p>Uit de variantie wordt ook de standaardafwijking (EN: standard deviation) berekend, die nog vaker gebruikt wordt.</p> <p>De variantie en standaardafwijking zijn gevoelig voor uitschieters. Bij data die niet normaal verdeeld zijn, vormen gemiddelde en standaardafwijking geen goede samenvatting van de data. In dat geval kan de mediaan en interkwartielafstand als alternatief dienen.</p>"},{"location":"nl/variantie/#variantie-van-een-steekproef","title":"variantie van een steekproef","text":"<p>De variantie \\(s^2\\) van een steekproef \\(X = \\{x_1, \\ldots, x_n\\}\\) van grootte \\(n\\) met gemiddelde \\(\\overline{x}\\) wordt als volgt berekend:</p> \\[s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2\\]"},{"location":"nl/variantie/#standaardafwijking-van-een-steekproef","title":"standaardafwijking van een steekproef","text":"<p>De standaardafwijking is de vierkantswortel van de variantie:</p> \\[s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2}\\]"},{"location":"nl/variantie/#variantie-van-een-populatie","title":"variantie van een populatie","text":"<p>De variantie \\(\\sigma\\) van een populatie van grootte \\(N\\) met gemiddelde \\(\\mu\\) wordt als volgt berekend:</p> \\[\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]"},{"location":"nl/variantie/#standaardafwijking-van-een-populatie","title":"standaardafwijking van een populatie","text":"<p>De standaardafwijking is de vierkantswortel van de variantie:</p> \\[\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2}\\]"},{"location":"nl/variantie/#variantie-en-standaardafwijking-van-een-discrete-stochastische-variabele","title":"variantie en standaardafwijking van een discrete stochastische variabele","text":"<p>De variantie \\(\\sigma_X^2\\) van een discrete stochastische variabele \\(X\\) met verwachtingswaarde \\(\\mu_X\\) wordt als volgt berekend:</p> \\[\\sigma_X^2 = \\sum_x (x - \\mu_X)^2 \\cdot P(X = x)\\] <p>De standaardafwijking is dan \\(\\sigma_X = \\sqrt{\\sigma_X^2}\\).</p>"},{"location":"nl/variantie/#variantie-en-standaardafwijking-van-een-continue-stochastische-variabele","title":"variantie en standaardafwijking van een continue stochastische variabele","text":"<p>De variantie \\(\\sigma_X^2\\) van een continue stochastische variabele \\(X\\) met verwachtingswaarde \\(\\mu_X\\) wordt als volgt berekend:</p> \\[\\sigma_X^2 = \\int_{-\\infty}^{+\\infty} (x - \\mu_X)^2 \\cdot f_X(x) \\, \\mathrm{d}x\\] <p>De standaardafwijking is opnieuw \\(\\sigma_X = \\sqrt{\\sigma_X^2}\\).</p>"},{"location":"nl/verband/","title":"verband","text":"<p>(EN: association)</p> <p>Bij analyse van twee variabelen spreken we van een verband als de waarden van de ene variabele systematisch veranderen als de waarden van de andere variabele veranderen. Met andere woorden, als je de waarde van de ene variabele kent, dan kan je -tot op zekere hoogte- de waarde van de andere variabele voorspellen.</p> <p>Meestal gaan we er van uit dat de ene variabele een zekere invloet uitoefent op de andere. De variabele waarvan we vermoeden dat die de invloed uitoefent, noemen we de onafhankelijke variabele. De variabele waarvan we vermoeden dat ze be\u00efnvloed wordt, noemen we de afhankelijke variabele.</p> <p>Onderzoekers moeten er op letten dat, als er een verband gevonden wordt tussen twee variabelen, dat niet noodzakelijk een oorzakelijk verband impliceert. De \"invloed\" kan in de omgekeerde richting gaan, of beide variabelen kunnen be\u00efnvloed worden door een derde, niet onderzochte, variabele. Een oorzakelijk verband aantonen vraagt een specifieke onderzoeksopzet, waarbij de onderzoeker de invloed van alle andere variabelen uitsluit.</p>"},{"location":"nl/waarde-verwachte/","title":"waarde, verwachte","text":"<p>(EN: value, expected)</p> <p>De verwachte waarde van een stochastische variabele is het gemiddelde van alle waarden die de variabele kan aannemen, gewogen met de kans dat die waarde optreedt.</p> <p>Voor een discrete stochastische variabele noteren we de verwachte waarde als \\(\\mu_X\\) of \\(E(X)\\) en berekenen we het als volgt:</p> \\[\\mu_x = \\sum_{i=1}^{n} x_i \\cdot P(X = x_i)\\] <p>met \\(\\Omega = {x_1, \\ldots, x_n}\\) de uitkomstenruimte van \\(X\\).</p> <p>Voor een continue stochastische variabele krijg je:</p> \\[\\mu_x = \\int_{-\\infty}^{+\\infty} x \\cdot f(x) \\, \\mathrm{d}x\\] <p>waarbij \\(f(x)\\) de kansdichtheidsfunctie is.</p> <p>Je kan ook de variantie en standaardafwijking van een stochastische variabele berekenen.</p>"},{"location":"nl/waarneming/","title":"waarneming","text":"<p>(EN: observation)</p> <p>Een waarneming is een individuele meting of waarde binnen een steekproef of stochastische variabele.</p>"},{"location":"nl/z-score/","title":"z-score","text":"<p>(EN: z-score, standard score)</p> <p>De z-score is een getal dat aangeeft hoeveel standaardafwijkingen een bepaalde waarde afwijkt van het gemiddelde. </p> <p>De z-score van een waarneming \\(x\\) uit een stochastische variabele \\(X\\) met verwachtingswaarde \\(\\mu\\) en standaardafwijking \\(\\sigma\\) is gegeven door:</p> \\[z = \\frac{x - \\mu}{\\sigma}\\]"},{"location":"nl/z-toets/","title":"z-toets","text":"<p>(EN: z-test)</p> <p>De z-toets is een statistische hypothesetoets om een uitspraak over het populatiegemiddelde te verifi\u00ebren, meer bepaald of het populatiegemiddelde \\(\\mu\\) gelijk is aan een bepaalde waarde, genoteerd als \\(\\mu_0\\).</p> <p>De z-toets kan gebruikt worden onder voorwaarde dat:</p> <ul> <li>de steekproef aselect is</li> <li>de steekproef groot genoeg is (\\(n \\geq 30\\))</li> <li>de toetsingsgrootheid normaal verdeeld is</li> <li>de standaardafwijking van de populatie \\(\\sigma\\) gekend is</li> </ul> <p>We gaan er in eerste instantie van uit dat deze uitspraak waar is, dus dat \\(\\mu = \\mu_0\\). Dit is de nulhypothese. Dan geldt de centrale limietstelling en volgt het steekproefgemiddelde een normale verdeling met verwachtingswaarde \\(\\mu_0\\) en standaardafwijking \\(\\sigma/\\sqrt{n}\\).</p> <p>De toetsingsgrootheid is dan het steekproefgemiddelde. Deze zal afwijken van de verwachtingswaarde \\(\\mu_0\\), maar de vraag is in hoeverre dat verschil significant is.</p> <p>Er bestaan drie varianten van deze toets:</p> <ul> <li>Rechtszijdig:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu &gt; \\mu_0\\)</li> <li>overschrijdingskans: \\(p = P(Z &gt; z)\\) met \\(z\\) de z-score \\(z = \\frac{\\overline{x} - \\mu_0}{\\sigma/\\sqrt{n}}\\)</li> <li>kritieke grenswaarde: \\(g = \\overline{x} + z_{\\alpha} \\frac{\\sigma}{\\sqrt{n}}\\) met \\(z_{\\alpha}\\) zodat \\(P(Z &gt; z_{\\alpha}) = \\alpha\\)</li> <li>verwerp de nulhypothese als \\(\\overline{x} &gt; g\\)</li> </ul> </li> <li>Linkszijdig:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu &lt; \\mu_0\\)</li> <li>overschrijdingskans: \\(p = P(Z &lt; z)\\)</li> <li>kritieke grenswaarde: \\(g = \\overline{x} - z_{\\alpha} \\frac{\\sigma}{\\sqrt{n}}\\)</li> <li>verwerp de nulhypothese als \\(\\overline{x} &lt; g\\)</li> </ul> </li> <li>Tweezijdig:<ul> <li>\\(H_0\\): \\(\\mu = \\mu_0\\), \\(H_1\\): \\(\\mu \\neq \\mu_0\\)</li> <li>overschrijdingskans: \\(p = 2P(Z &gt; z)\\)</li> <li>kritieke grenswaarden:<ul> <li>\\(g_1 = \\overline{x} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)</li> <li>\\(g_2 = \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\)</li> </ul> </li> <li>verwerp de nulhypothese als \\(\\overline{x} &lt; g_1\\) of \\(\\overline{x} &gt; g_2\\)</li> </ul> </li> </ul> <p>In de praktijk wordt de \\(z\\)-toets zelden gebruikt omdat de populatiestandaardafwijking meestal niet gekend is. In dat geval wordt eerder de t-toets gebruikt.</p>"}]}